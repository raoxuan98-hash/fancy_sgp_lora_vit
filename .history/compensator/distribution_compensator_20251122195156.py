# -*- coding: utf-8 -*-
import copy
import logging
import time
from typing import Dict, Optional, Tuple

import torch
import torch.nn as nn
from torch.utils.data import DataLoader

from compensator.gaussian_statistics import GaussianStatistics
from compensator.sldc_linear import LinearCompensator
from compensator.sldc_weaknonlinear import WeakNonlinearCompensator
from compensator.sldc_attention import AttentionCompensator


def log_time_usage(operation_name: str, start_time: float, end_time: float):
    """记录时间损耗情况"""
    elapsed_time = end_time - start_time
    logging.info(f"[Time] {operation_name}: {elapsed_time:.4f}s")


class DistributionCompensator:
    """
    负责从特征对 (features_before, features_after) 构建多种补偿变体。
    输出 variants: Dict[str, Dict[int, GaussianStatistics]]
    """
    def __init__(
        self,
        device: str = "cuda",
        auxiliary_data_size: int = 1024,
        compensator_types = None,
        feature_combination_type: str = "combined"
    ):
        self.device = device
        self.auxiliary_data_size = auxiliary_data_size
        self.feature_combination_type = feature_combination_type
        
        # 补偿器类型控制
        if compensator_types is None:
            # 默认使用所有补偿器类型
            self.compensator_types = ["SeqFT", "SeqFT + linear", "SeqFT + weaknonlinear", "SeqFT + Hopfield"]
        else:
            self.compensator_types = compensator_types

        # 特征和缓存相关
        self.feature_dim = None
        self.cached_Z = None
        self.aux_loader = None

        # 变体存储
        self.variants = self._initialize_variants()

    def _get_gpu_memory_info(self) -> Dict[str, float]:
        """获取当前GPU显存信息"""
        if not torch.cuda.is_available():
            return {"allocated": 0.0, "reserved": 0.0, "max_allocated": 0.0}
        
        return {
            "allocated": torch.cuda.memory_allocated() / 1024**3,  # GB
            "reserved": torch.cuda.memory_reserved() / 1024**3,    # GB
            "max_allocated": torch.cuda.max_memory_allocated() / 1024**3  # GB
        }

    def _log_memory_usage(self, operation_name: str, start_memory: Dict[str, float], end_memory: Dict[str, float]):
        """记录显存使用情况"""
        allocated_diff = end_memory["allocated"] - start_memory["allocated"]
        reserved_diff = end_memory["reserved"] - start_memory["reserved"]
        
        logging.info(
            f"[GPU Memory] {operation_name}: "
            f"Allocated={end_memory['allocated']:.2f}GB "
            f"(+{allocated_diff:.2f}GB), "
            f"Reserved={end_memory['reserved']:.2f}GB "
            f"(+{reserved_diff:.2f}GB), "
            f"Max={end_memory['max_allocated']:.2f}GB"
        )

    def _initialize_variants(self) -> Dict[str, Dict]:
        """根据compensator_types初始化指定的补偿变体结构"""
        variants = {}
        for comp_type in self.compensator_types:
            variants[comp_type] = {}
        return variants

    # ============================================================
    #                  特征抽取与统计构建
    # ============================================================
    
    @torch.no_grad()
    def extract_features_before_after(
        self,
        model_before: nn.Module,
        model_after: nn.Module,
        data_loader: DataLoader
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """同时提取前后模型的特征"""
        operation_name = "extract_features_before_after"
        start_memory = self._get_gpu_memory_info()
        start_time = time.time()
        # logging.info(f"[GPU Memory] Starting {operation_name}...")
        
        model_before.eval()
        model_after.eval()
        model_before.to(self.device)
        model_after.to(self.device)

        feats_before, feats_after, labels = [], [], []
        for batch in data_loader:
            inputs = batch[0]
            targets = batch[1]
            inputs = inputs.to(self.device)
            feats_before.append(model_before(inputs).cpu())
            feats_after.append(model_after(inputs).cpu())
            labels.append(targets)
            
        result = (
            torch.cat(feats_before),
            torch.cat(feats_after),
            torch.cat(labels)
        )
        
        end_time = time.time()
        end_memory = self._get_gpu_memory_info()
        
        # 记录时间损耗
        log_time_usage(operation_name, start_time, end_time)
        self._log_memory_usage(operation_name, start_memory, end_memory)
        
        return result

    @torch.no_grad()
    def _extract_combined_features(
        self,
        model_before: nn.Module,
        model_after: nn.Module,
        current_loader: DataLoader):
        """
        一次性提取当前数据和辅助数据的组合特征，避免重复计算
        
        Returns:
            Tuple: (current_before, current_after, current_labels, combined_before, combined_after)
        """
        # 提取当前任务特征
        current_before, current_after, current_labels = self.extract_features_before_after(
            model_before, model_after, current_loader
        )
        
        current_cosine_sim = torch.nn.functional.cosine_similarity(current_before, current_after, dim=1).mean()
        current_norm_diff = (current_before.norm(p=2, dim=1) - current_after.norm(p=2, dim=1)).abs().mean()
        logging.info(f"[Feature Analysis] Current features - Cosine similarity: {current_cosine_sim:.4f}, Norm difference: {current_norm_diff:.4f}")
        
        # 初始化组合特征
        combined_before, combined_after = current_before, current_after
        aux_cosine_sim = None
        aux_norm_diff = None
        
        # 如果有辅助数据，合并特征
        if self.aux_loader is not None:
            aux_before, aux_after, _ = self.extract_features_before_after(
                model_before, model_after, self.aux_loader
            )

            combined_before = torch.cat([current_before, aux_before])
            combined_after = torch.cat([current_after, aux_after])
            
            # 计算辅助特征的余弦相似度和范数差异
            aux_cosine_sim = torch.nn.functional.cosine_similarity(aux_before, aux_after, dim=1).mean()
            aux_norm_diff = (aux_before.norm(p=2, dim=1) - aux_after.norm(p=2, dim=1)).abs().mean()
            logging.info(f"[Feature Analysis] Auxiliary features - Cosine similarity: {aux_cosine_sim:.4f}, Norm difference: {aux_norm_diff:.4f}")
        else:
            aux_before = None
            aux_after = None 

        return current_before, current_after, current_labels, aux_before, aux_after, combined_before, combined_after

    def _build_gaussian_statistics(
        self, 
        features: torch.Tensor, 
        labels: torch.Tensor
    ) -> Dict[int, GaussianStatistics]:
        """为每个类别构建高斯统计量"""
        features = features.cpu()
        labels = labels.cpu()
        unique_labels = torch.unique(labels)
        
        stats = {}
        for lbl in unique_labels:
            mask = (labels == lbl)
            feats_class = features[mask]
            
            # 计算均值和协方差
            mu = feats_class.mean(0)
            if feats_class.size(0) >= 2:
                cov = torch.cov(feats_class.T)
            else:
                cov = torch.eye(feats_class.size(1)) * 1e-4
                
            stats[int(lbl.item())] = GaussianStatistics(mu, cov)
            
        return stats

    # ============================================================
    #                  补偿器计算与变换
    # ============================================================
    
    def _compute_linear_transform(
        self,
        f_before: torch.Tensor,
        f_after: torch.Tensor,
        gamma: float = 0.1,
        temp: float = 1.0
    ) -> LinearCompensator:
        """计算线性变换补偿器"""
        operation_name = "LinearCompensator"
        start_memory = self._get_gpu_memory_info()
        start_time = time.time()
        
        compensator = LinearCompensator(
            input_dim=f_before.size(1),
            gamma=gamma,
            temp=temp,
            device=self.device,
        )
        compensator.train(f_before.to(self.device), f_after.to(self.device))
        
        end_time = time.time()
        end_memory = self._get_gpu_memory_info()
        
        # 记录时间损耗
        log_time_usage(operation_name, start_time, end_time)
        self._log_memory_usage(operation_name, start_memory, end_memory)
        
        return compensator

    def _compute_weaknonlinear_transform(
        self,
        f_before: torch.Tensor,
        f_after: torch.Tensor
    ) -> WeakNonlinearCompensator:
        """计算弱非线性变换补偿器"""
        operation_name = "WeakNonlinearCompensator"
        start_memory = self._get_gpu_memory_info()
        start_time = time.time()
        
        compensator = WeakNonlinearCompensator(
            input_dim=f_before.size(1),
            device=self.device,
        )
        compensator.train(f_before.to(self.device), f_after.to(self.device))
        
        end_time = time.time()
        end_memory = self._get_gpu_memory_info()
        
        # 记录时间损耗
        log_time_usage(operation_name, start_time, end_time)
        self._log_memory_usage(operation_name, start_memory, end_memory)
        
        return compensator

    def _compute_attention_transform(
        self,
        f_before: torch.Tensor,
        f_after: torch.Tensor
    ) -> AttentionCompensator:
        """计算注意力变换补偿器"""
        operation_name = "AttentionCompensator"
        start_memory = self._get_gpu_memory_info()
        start_time = time.time()
        
        compensator = AttentionCompensator(
            input_dim=f_before.size(1),
            device=self.device,
        )
        compensator.train(f_before.to(self.device), f_after.to(self.device))
        
        end_time = time.time()
        end_memory = self._get_gpu_memory_info()
        
        # 记录时间损耗
        log_time_usage(operation_name, start_time, end_time)
        self._log_memory_usage(operation_name, start_memory, end_memory)
        
        return compensator

    def _update_variants_with_transforms(
        self,
        task_id: int,
        current_stats: Dict[int, GaussianStatistics],
        combined_before: torch.Tensor,
        combined_after: torch.Tensor
    ):
        """根据compensator_types使用指定的变换更新变体"""
        if task_id <= 1:
            # 对于第一个任务，直接使用当前统计量初始化所有变体
            for variant_key in self.variants:
                if variant_key != "SeqFT":  # SeqFT已经在主流程中更新
                    self.variants[variant_key].update(copy.deepcopy(current_stats))
            return
            
        # 只计算需要的变换
        transforms = {}
        if "SeqFT + linear" in self.compensator_types:
            transforms["linear"] = self._compute_linear_transform(combined_before, combined_after)

        if "SeqFT + weaknonlinear" in self.compensator_types:
            transforms["weaknonlinear"] = self._compute_weaknonlinear_transform(combined_before, combined_after)
            
        if "SeqFT + Hopfield" in self.compensator_types:
            transforms["Hopfield"] = self._compute_attention_transform(combined_before, combined_after)
        
        # 应用变换到现有统计量并更新
        for transform_name, transform in transforms.items():
            variant_key = f"SeqFT + {transform_name}"
            
            # 对现有统计量进行补偿
            start_memory = self._get_gpu_memory_info()
            start_time = time.time()
            # logging.info(f"[GPU Memory] Starting compensation for {variant_key}...")
            
            compensated_existing_stats = transform.compensate(self.variants[variant_key])
            
            end_time = time.time()
            end_memory = self._get_gpu_memory_info()
            allocated_diff = end_memory["allocated"] - start_memory["allocated"]
            reserved_diff = end_memory["reserved"] - start_memory["reserved"]
            
            # 记录时间损耗
            log_time_usage(f"Compensation for {variant_key}", start_time, end_time)
            
            logging.info(
                f"[GPU Memory] Compensation for {variant_key} completed: "
                f"Allocated={end_memory['allocated']:.2f}GB (+{allocated_diff:.2f}GB), "
                f"Reserved={end_memory['reserved']:.2f}GB (+{reserved_diff:.2f}GB)"
            )
            
            # 添加当前任务的统计量
            compensated_existing_stats.update(copy.deepcopy(current_stats))
            
            self.variants[variant_key] = compensated_existing_stats

    # ============================================================
    #                  主入口方法
    # ============================================================
    
    def build_all_variants(
        self,
        task_id: int,
        model_before: nn.Module,
        model_after: nn.Module,
        data_loader: DataLoader
    ) -> Dict[str, Dict[int, GaussianStatistics]]:
        # 参数验证
        if task_id < 0:
            raise ValueError("task_id must be non-negative")
        
        operation_name = "build_all_variants"
        start_memory = self._get_gpu_memory_info()
        start_time = time.time()
        logging.info(f"[GPU Memory] Starting {operation_name} for task {task_id}...")
            
        # 一次性提取所有需要的特征，避免重复计算
        (current_before, current_after, current_labels, aux_before, aux_after,
         combined_before, combined_after) = self._extract_combined_features(
            model_before, model_after, data_loader)
        
        # 初始化特征维度缓存
        if self.feature_dim is None:
            self.feature_dim = current_after.size(1)
            self.cached_Z = torch.randn(50000, self.feature_dim)
        
        # 构建当前任务的统计量
        current_stats = self._build_gaussian_statistics(current_after, current_labels)
        
        # 更新基础变体
        self.variants["SeqFT"].update(copy.deepcopy(current_stats))
        
        
        if self.feature_combination_type == "combined":

            f_before = combined_before
            f_after = combined_after
        elif self.feature_combination_type == "aux_only":
            f_before = aux_before
            f_after = aux_after

        elif self.feature_combination_type == "current_only":
            f_before = current_before
            f_after = current_after
        else:
            raise ValueError(f"Invalid feature_combination_type: {self.feature_combination_type}")

        self._update_variants_with_transforms(
            task_id, current_stats, f_before, f_after)
        
        logging.info(f"[INFO] DistributionCompensator built {len(self.variants)} variants for task {task_id}.")
        
        # 清理GPU缓存
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        end_time = time.time()
        end_memory = self._get_gpu_memory_info()
        
        # 记录时间损耗
        log_time_usage(f"{operation_name} for task {task_id}", start_time, end_time)
        self._log_memory_usage(operation_name, start_memory, end_memory)
            
        return self.variants

    def set_auxiliary_loader(self, aux_loader: DataLoader):
        """设置辅助数据加载器"""
        self.aux_loader = aux_loader

    def clear_cache(self):
        """清除缓存"""
        self.cached_Z = None

    def get_variant_names(self) -> list:
        """获取所有变体名称"""
        return list(self.variants.keys())