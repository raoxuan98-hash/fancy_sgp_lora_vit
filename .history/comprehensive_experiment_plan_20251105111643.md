# 全面实验方案设计

## 项目概述

本项目实现了基于LoRA的增量学习方法，包含以下核心组件：
- **LoRA变体**：basic_lora, sgp_lora, nsp_lora
- **知识蒸馏**：支持特征蒸馏和logit蒸馏
- **分布补偿**：AMDC（注意力机制分布补偿）
- **分类器**：RGDA、LDA、QDA、SGD等多种分类器

## 实验架构

### 主实验（Main Experiments）

#### 1. 基准设置（Benchmark Setup）

| 数据集 | 任务设置 | 初始类别数 | 每任务新增类别数 | 总任务数 |
|--------|----------|------------|------------------|----------|
| CIFAR-100 | 10 tasks × 10 classes | 10 | 10 | 10 |
| ImageNet-R | 10 tasks × 20 classes | 20 | 20 | 10 |
| CUB-200 | 10 tasks × 20 classes | 20 | 20 | 10 |
| Cars-196 | 10 tasks × 20 classes | 20 | 20 | 10 (最后一任务6类) |

#### 2. 对比方法（Baselines）

1. **LoRA (基础版本)**：使用basic_lora类型
2. **LoRA + Distillation**：设置gamma_kd=1.0，update_teacher_each_task=True, distillation_transform='identity'
3. **LoRA-NSP**：使用nsp_lora类型，设置nsp_weight=0.05
4. **完整方法**：sgp_lora + RGDA + AMDC

#### 3. 评估指标

- **Last-Acc**：所有任务结束后在所有类别上的平均准确率
- **Avg-Acc**：所有任务的平均准确率

### 消融研究（Ablation Study）

#### 1. 组件消融

| 变体 | LoRA-SGP | AMDC | 说明 |
|------|----------|------|------|
| LoRA-SGP (full method) | ✅ | ✅ | 完整方法 |
| w/o SGP | ❌ | ✅ | 使用basic_lora而非sgp_lora |
| w/o AMDC | ✅ | ❌ | 报道没有矫正的精度 |
| w/o both lora_sgp & AMDC | ❌ | ❌ | 仅SGP+原始分类器 |

#### 2. LoRA-SGP消融实验

- **实验1**：
  - 不同的weight_temp：[1.0, 2.0, 4.0]
  - 不同的weight_p：[1.0, 2.0]
  
- **实验2**：
  - 不同的weight_kind的影响
  - 选择ImageNet-R和Cars-196两个数据集

#### 3. AMDC消融实验

- **AMDC本身的消融**：
  - 仅补偿均值
  - 仅补偿协方差
  - 同时补偿均值和协方差
  - 不同的注意力计算温度

- **AMDC与其他补偿方法的对比**：
  - 与linear_transform/weaknonlinear_transform/nonlinear_transform的结果对比
  - 效率对比（运行时间对比）

#### 4. RGDA消融实验

- 超参数敏感性分析
- 与SGD-based refinement/NCM/LDA分类器进行对比

### 补充实验方案

#### 1. 长序列任务实验

将CIFAR-100划分为20个任务（每任务5类），验证方法在长期学习中的表现。

#### 2. 跨架构泛化性

测试不同ViT架构的泛化性能：
- vit-b-p16-mocov3（默认）
- vit-b-p16
- vit-b-p-clip

## 实验执行策略

### 1. 并行化设计

- **数据集级并行**：不同数据集可以在不同GPU上并行运行
- **方法级并行**：不同对比方法可以并行执行
- **参数级并行**：超参数搜索可以并行执行

### 2. 资源管理

- **GPU分配**：动态分配GPU资源，避免资源冲突
- **内存管理**：合理设置batch_size，避免OOM
- **存储管理**：自动清理中间结果，只保留关键日志

### 3. 实验监控

- **实时日志**：使用tail -f实时监控实验进度
- **结果汇总**：自动生成实验结果汇总表
- **异常处理**：自动重试失败的实验

## 实验脚本设计

### 1. 主实验脚本

- `run_main_experiments.sh`：运行所有主实验
- `run_baseline_comparison.sh`：运行基线对比实验
- `run_full_method.sh`：运行完整方法实验

### 2. 消融研究脚本

- `run_component_ablation.sh`：组件消融实验
- `run_sgp_ablation.sh`：SGP参数消融实验
- `run_amdc_ablation.sh`：AMDC消融实验

### 3. 补充实验脚本

- `run_long_sequence.sh`：长序列任务实验
- `run_cross_architecture.sh`：跨架构泛化实验

### 4. 结果分析脚本

- `collect_results.py`：收集和整理实验结果
- `generate_tables.py`：生成结果表格
- `plot_results.py`：绘制结果图表

## 预期结果分析

### 1. 主实验结果

预期完整方法（sgp_lora + RGDA + AMDC）在所有数据集上都能取得最佳性能，特别是在长序列学习场景中。

### 2. 消融研究结果

- SGP和AMDC组件应该都有助于提升性能
- weight_temp和weight_p的最优值可能因数据集而异
- AMDC应该比其他补偿方法更高效

### 3. 补充实验结果

- 长序列任务中，方法应该表现出更好的稳定性
- 跨架构实验应该验证方法的泛化能力

## 实验时间估算

### 1. 主实验

- 4种方法 × 4个数据集 × 3个种子 = 48个实验
- 每个实验约2-4小时
- 总计约96-192小时

### 2. 消融研究

- 组件消融：4种变体 × 4个数据集 × 3个种子 = 48个实验
- SGP消融：3×2×2×3 = 36个实验
- AMDC消融：约30个实验
- 总计约114个实验

### 3. 补充实验

- 长序列任务：4种方法 × 1个数据集 × 3个种子 = 12个实验
- 跨架构：3种架构 × 4个数据集 × 3个种子 = 36个实验
- 总计约48个实验

**总计约210个实验，预计需要300-500小时的计算时间**

## 实验风险与缓解策略

### 1. 计算资源不足

- **风险**：实验数量庞大，可能导致计算资源不足
- **缓解**：优先执行主实验，消融研究可以分批进行

### 2. 实验失败

- **风险**：长时间实验可能因各种原因失败
- **缓解**：实现自动重试机制，定期保存检查点

### 3. 结果不一致

- **风险**：不同运行之间结果可能不一致
- **缓解**：使用固定随机种子，多次运行取平均

## 下一步行动

1. 首先实现主实验脚本
2. 实现基本的并行执行框架
3. 逐步添加消融研究脚本
4. 实现结果收集和分析工具
5. 优化实验执行效率