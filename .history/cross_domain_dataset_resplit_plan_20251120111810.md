# Cross-Domain数据集重新划分方案

## 1. 数据集不平衡现状分析

根据分析结果，当前cross-domain数据集存在严重的不平衡问题：

### 主要问题
- **测试样本数量极不平衡**：最小1,880 (dtd) vs 最大25,250 (food-101)，不平衡比率高达13.43x
- **平均每类测试样本数差异巨大**：最小28.97 (cub200_224) vs 最大1000.00 (mnist)
- **变异系数高达0.808**，表明数据分布极不均匀

### 具体数据集情况
1. **样本过少的 dataset**：
   - dtd: 1,880测试样本，平均每类40个
   - fgvc-aircraft: 3,333测试样本，平均每类33.33个
   - cub200_224: 5,794测试样本，平均每类28.97个

2. **样本过多的 dataset**：
   - food-101: 25,250测试样本，平均每类250个
   - resisc45: 25,200测试样本，平均每类560个
   - mnist: 10,000测试样本，平均每类1000个

## 2. 重新划分策略设计

### 目标
- 将每个类别的测试样本数量限制到128
- 将每个类别的训练样本数量限制到128
- 如果测试样本数量小于128，从训练样本中采样补充到128
- 保持与现有DataManager的兼容性

### 算法策略

#### 2.1 基本原则
1. **上限约束**：每个类别最多128个样本（训练集和测试集）
2. **下限保证**：每个类别至少128个测试样本
3. **平衡补充**：测试样本不足时从训练样本中随机采样
4. **随机性控制**：使用固定种子确保可重现性

#### 2.2 具体算法流程

对于每个数据集的每个类别：

```
算法：平衡采样
输入：原始训练集(train_data, train_labels)，测试集(test_data, test_labels)，最大样本数=128
输出：平衡后的训练集和测试集

1. 统计每个类别的原始样本数：
   - train_count[class] = 训练集中类别class的样本数
   - test_count[class] = 测试集中类别class的样本数

2. 对每个类别class执行：
   a. 如果test_count[class] >= 128：
      - 随机采样128个测试样本作为新测试集
      - 如果train_count[class] >= 128：
         * 随机采样128个训练样本作为新训练集
      - 否则：
         * 保留所有训练样本作为新训练集
   
   b. 如果test_count[class] < 128：
      - 保留所有测试样本
      - 需要补充的样本数 = 128 - test_count[class]
      - 如果train_count[class] >= 需要补充的样本数：
         * 从训练集中随机采样需要补充的样本数，移动到测试集
         * 从剩余训练样本中随机采样最多128个作为新训练集
      - 否则：
         * 将所有训练样本移动到测试集
         * 测试集总样本数 = test_count[class] + train_count[class]
         * 新训练集为空（或使用数据增强）
```

#### 2.3 特殊情况处理

1. **极端不平衡类别**：
   - 如果某类别总样本数（训练+测试）仍小于128：
     - 保留所有样本
     - 在元数据中标记为"低样本类别"
     - 建议后续使用数据增强技术

2. **数据增强策略**（可选）：
   - 对样本数极少的类别应用数据增强
   - 包括旋转、翻转、颜色抖动等基本变换
   - 仅在训练集中应用增强

## 3. 实现架构设计

### 3.1 目录结构
```
balanced_datasets/
├── metadata/
│   ├── original_distribution.json      # 原始数据分布信息
│   ├── balanced_distribution.json     # 平衡后数据分布信息
│   ├── sampling_config.json           # 采样配置和种子
│   └── dataset_statistics.json        # 详细统计信息
├── cifar100_224/
│   ├── train/
│   │   ├── class_0/
│   │   ├── class_1/
│   │   └── ...
│   ├── test/
│   │   ├── class_0/
│   │   ├── class_1/
│   │   └── ...
│   └── label.txt
├── cub200_224/
│   └── ...
└── ...
```

### 3.2 核心组件

#### 3.2.1 数据集重新划分器 (DatasetResplitter)
- 负责执行具体的采样算法
- 处理不同类型的数据集（数组vs路径）
- 生成详细的采样日志

#### 3.2.2 元数据管理器 (MetadataManager)
- 记录原始数据分布
- 记录采样过程和参数
- 生成统计报告

#### 3.2.3 平衡数据管理器 (BalancedDataManager)
- 继承现有的CrossDomainDataManagerCore
- 适配新的数据集路径结构
- 保持API兼容性

## 4. 兼容性设计

### 4.1 与现有系统的兼容
1. **保持相同的API接口**：新数据管理器应与现有CrossDomainDataManagerCore具有相同的方法签名
2. **数据格式一致**：保持相同的数据结构和标签格式
3. **配置参数兼容**：支持现有的所有配置参数

### 4.2 向后兼容策略
1. **原始数据保留**：不修改原始数据集
2. **可选使用**：通过配置参数选择使用原始或平衡数据集
3. **性能对比**：支持在同一实验中对比原始和平衡数据集的性能

## 5. 质量保证措施

### 5.1 数据完整性检查
- 验证重新划分后每个类别的样本数量
- 检查图像文件的有效性
- 确保标签文件的正确性

### 5.2 可重现性保证
- 使用固定随机种子
- 记录所有采样参数
- 提供完整的采样日志

### 5.3 性能监控
- 记录原始vs平衡数据集的性能差异
- 分析平衡策略对不同类别的影响
- 提供详细的实验对比报告

## 6. 实施计划

### 阶段1：核心算法实现
- 实现DatasetResplitter类
- 实现基本的平衡采样算法
- 创建元数据记录系统

### 阶段2：数据管理器适配
- 实现BalancedDataManager类
- 确保与现有系统的兼容性
- 添加配置选项

### 阶段3：测试与验证
- 运行完整的数据集重新划分
- 验证数据质量和完整性
- 进行兼容性测试

### 阶段4：文档与示例
- 编写详细的使用文档
- 提供代码示例
- 创建最佳实践指南

## 7. 预期效果

### 7.1 数据平衡性改善
- 所有类别的测试样本数统一为128（除极端情况）
- 训练样本数控制在128以内
- 大幅降低数据集间的不平衡比率

### 7.2 实验效果预期
- 减少数量多的数据集对整体性能的过度影响
- 提高少数样本数据集的训练效果
- 可能带来更公平和稳定的跨域学习性能

### 7.3 系统改进
- 提供更可控的实验环境
- 支持更精确的消融实验
- 便于研究数据不平衡对模型性能的影响