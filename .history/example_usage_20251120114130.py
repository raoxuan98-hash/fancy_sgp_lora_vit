#!/usr/bin/env python3
"""
å¹³è¡¡æ•°æ®é›†ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨é‡æ–°åˆ’åˆ†åçš„å¹³è¡¡æ•°æ®é›†è¿›è¡Œå®éªŒ
"""

import os
import sys
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from dataset_resplitter import DatasetResplitter
from utils.balanced_cross_domain_data_manager import create_balanced_data_manager

def example_resplit_datasets():
    """ç¤ºä¾‹ï¼šé‡æ–°åˆ’åˆ†æ•°æ®é›†"""
    print("=" * 60)
    print("ç¤ºä¾‹1ï¼šé‡æ–°åˆ’åˆ†æ•°æ®é›†")
    print("=" * 60)
    
    # é€‰æ‹©å‡ ä¸ªå°æ•°æ®é›†è¿›è¡Œæ¼”ç¤º
    demo_datasets = ['dtd', 'mnist', 'cifar100_224']
    
    # åˆ›å»ºé‡æ–°åˆ’åˆ†å™¨
    resplitter = DatasetResplitter(
        max_samples_per_class=64,  # ä½¿ç”¨64ä¸ªæ ·æœ¬è¿›è¡Œå¿«é€Ÿæ¼”ç¤º
        seed=42,
        output_dir="example_balanced_datasets"
    )
    
    # å¤„ç†æ•°æ®é›†
    results = resplitter.resplit_all_datasets(demo_datasets)
    
    print("æ•°æ®é›†é‡æ–°åˆ’åˆ†å®Œæˆï¼")
    for dataset_name, result in results.items():
        if 'error' in result:
            print(f"âŒ {dataset_name}: {result['error']}")
        else:
            print(f"âœ… {dataset_name}: å¤„ç†æˆåŠŸ")
    
    return True

def example_use_balanced_manager():
    """ç¤ºä¾‹ï¼šä½¿ç”¨å¹³è¡¡æ•°æ®ç®¡ç†å™¨"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹2ï¼šä½¿ç”¨å¹³è¡¡æ•°æ®ç®¡ç†å™¨")
    print("=" * 60)
    
    # ä½¿ç”¨åˆšåˆšåˆ›å»ºçš„å¹³è¡¡æ•°æ®é›†
    demo_datasets = ['dtd', 'mnist', 'cifar100_224']
    
    # åˆ›å»ºå¹³è¡¡æ•°æ®ç®¡ç†å™¨
    manager = create_balanced_data_manager(
        dataset_names=demo_datasets,
        balanced_datasets_root="example_balanced_datasets",
        use_balanced_datasets=True,
        log_level=logging.WARNING
    )
    
    print(f"âœ… å¹³è¡¡æ•°æ®ç®¡ç†å™¨åˆ›å»ºæˆåŠŸ")
    print(f"   æ€»ä»»åŠ¡æ•°: {manager.nb_tasks}")
    print(f"   æ€»ç±»åˆ«æ•°: {manager.num_classes}")
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = manager.get_balanced_statistics()
    print(f"\nğŸ“Š å¹³è¡¡åç»Ÿè®¡ä¿¡æ¯:")
    for dataset_name, stat in stats.items():
        print(f"   {dataset_name}:")
        print(f"     è®­ç»ƒæ ·æœ¬: {stat['total_train_samples']}")
        print(f"     æµ‹è¯•æ ·æœ¬: {stat['total_test_samples']}")
        print(f"     è®­ç»ƒæ¯ç±»: min={stat['train_per_class']['min']}, "
              f"max={stat['train_per_class']['max']}")
        print(f"     æµ‹è¯•æ¯ç±»: min={stat['test_per_class']['min']}, "
              f"max={stat['test_per_class']['max']}")
    
    return True

def example_data_loading():
    """ç¤ºä¾‹ï¼šæ•°æ®åŠ è½½å’Œä½¿ç”¨"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹3ï¼šæ•°æ®åŠ è½½å’Œä½¿ç”¨")
    print("=" * 60)
    
    demo_datasets = ['dtd', 'mnist']
    
    # åˆ›å»ºå¹³è¡¡æ•°æ®ç®¡ç†å™¨
    manager = create_balanced_data_manager(
        dataset_names=demo_datasets,
        balanced_datasets_root="example_balanced_datasets",
        use_balanced_datasets=True,
        log_level=logging.WARNING
    )
    
    # æ¼”ç¤ºæ•°æ®åŠ è½½
    for task_id in range(manager.nb_tasks):
        dataset_name = manager.datasets[task_id]['name']
        print(f"\nğŸ” åŠ è½½æ•°æ®é›† {dataset_name} (ä»»åŠ¡ {task_id}):")
        
        try:
            # åŠ è½½è®­ç»ƒé›†
            train_dataset = manager.get_subset(task_id, source="train", mode="train")
            train_length = len(train_dataset) if hasattr(train_dataset, '__len__') else 'unknown'
            print(f"   âœ… è®­ç»ƒé›†åŠ è½½æˆåŠŸ: {train_length} ä¸ªæ ·æœ¬")
            
            # åŠ è½½æµ‹è¯•é›†
            test_dataset = manager.get_subset(task_id, source="test", mode="test")
            test_length = len(test_dataset) if hasattr(test_dataset, '__len__') else 'unknown'
            print(f"   âœ… æµ‹è¯•é›†åŠ è½½æˆåŠŸ: {test_length} ä¸ªæ ·æœ¬")
            
            # è·å–ç¬¬ä¸€ä¸ªæ ·æœ¬æŸ¥çœ‹
            try:
                train_sample_len = len(train_dataset)
                test_sample_len = len(test_dataset)
            except:
                train_sample_len = 0
                test_sample_len = 0
                
            if train_sample_len > 0 and test_sample_len > 0:
                train_sample, train_label, train_class_name = train_dataset[0]
                test_sample, test_label, test_class_name = test_dataset[0]
                
                print(f"   ğŸ“· è®­ç»ƒæ ·æœ¬å½¢çŠ¶: {train_sample.shape}")
                print(f"   ğŸ·ï¸  è®­ç»ƒæ ‡ç­¾: {train_label}, ç±»å: {train_class_name}")
                print(f"   ğŸ“· æµ‹è¯•æ ·æœ¬å½¢çŠ¶: {test_sample.shape}")
                print(f"   ğŸ·ï¸  æµ‹è¯•æ ‡ç­¾: {test_label}, ç±»å: {test_class_name}")
                
        except Exception as e:
            print(f"   âŒ åŠ è½½å¤±è´¥: {str(e)}")
            return False
    
    return True

def example_comparison():
    """ç¤ºä¾‹ï¼šä¸åŸå§‹æ•°æ®é›†æ¯”è¾ƒ"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹4ï¼šä¸åŸå§‹æ•°æ®é›†æ¯”è¾ƒ")
    print("=" * 60)
    
    demo_datasets = ['dtd', 'mnist']
    
    # åˆ›å»ºå¹³è¡¡æ•°æ®ç®¡ç†å™¨
    balanced_manager = create_balanced_data_manager(
        dataset_names=demo_datasets,
        balanced_datasets_root="example_balanced_datasets",
        use_balanced_datasets=True,
        log_level=logging.WARNING
    )
    
    # è·å–æ¯”è¾ƒç»“æœ
    comparison = balanced_manager.compare_with_original()
    
    print("ğŸ“Š åŸå§‹ vs å¹³è¡¡æ•°æ®é›†æ¯”è¾ƒ:")
    for dataset_name, comp in comparison.items():
        print(f"\nğŸ” {dataset_name}:")
        
        orig = comp['original']
        bal = comp['balanced']
        
        print(f"   è®­ç»ƒæ ·æœ¬: {orig['total_train_samples']} â†’ {bal['total_train_samples']}")
        print(f"   æµ‹è¯•æ ·æœ¬: {orig['total_test_samples']} â†’ {bal['total_test_samples']}")
        
        print(f"   è®­ç»ƒæ¯ç±»èŒƒå›´: {orig['train_per_class_stats']['min']}-{orig['train_per_class_stats']['max']} "
              f"â†’ {bal['train_per_class_stats']['min']}-{bal['train_per_class_stats']['max']}")
        
        print(f"   æµ‹è¯•æ¯ç±»èŒƒå›´: {orig['test_per_class_stats']['min']}-{orig['test_per_class_stats']['max']} "
              f"â†’ {bal['test_per_class_stats']['min']}-{bal['test_per_class_stats']['max']}")
        
        # è®¡ç®—æ”¹å–„ç¨‹åº¦
        if orig['test_per_class_stats']['min'] > 0:
            orig_imbalance = orig['test_per_class_stats']['max'] / orig['test_per_class_stats']['min']
            bal_imbalance = bal['test_per_class_stats']['max'] / bal['test_per_class_stats']['min']
            
            print(f"   æµ‹è¯•é›†ä¸å¹³è¡¡æ¯”ç‡: {orig_imbalance:.2f}x â†’ {bal_imbalance:.2f}x")
            
            if bal_imbalance < orig_imbalance:
                print(f"   âœ… ä¸å¹³è¡¡æ€§æ”¹å–„äº† {(orig_imbalance/bal_imbalance):.2f}x")
            else:
                print(f"   âš ï¸  ä¸å¹³è¡¡æ€§æœªæ”¹å–„")
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¹³è¡¡æ•°æ®é›†ä½¿ç”¨ç¤ºä¾‹")
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logging.basicConfig(level=logging.WARNING)
    
    examples = [
        ("é‡æ–°åˆ’åˆ†æ•°æ®é›†", example_resplit_datasets),
        ("ä½¿ç”¨å¹³è¡¡æ•°æ®ç®¡ç†å™¨", example_use_balanced_manager),
        ("æ•°æ®åŠ è½½å’Œä½¿ç”¨", example_data_loading),
        ("ä¸åŸå§‹æ•°æ®é›†æ¯”è¾ƒ", example_comparison)
    ]
    
    results = []
    for example_name, example_func in examples:
        try:
            result = example_func()
            results.append((example_name, result))
        except Exception as e:
            print(f"âŒ ç¤ºä¾‹ '{example_name}' å‡ºç°å¼‚å¸¸: {str(e)}")
            results.append((example_name, False))
    
    # è¾“å‡ºç»“æœæ‘˜è¦
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹è¿è¡Œç»“æœæ‘˜è¦")
    print("=" * 60)
    
    passed = 0
    for example_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{example_name}: {status}")
        if result:
            passed += 1
    
    print(f"\næ€»è®¡: {passed}/{len(results)} ä¸ªç¤ºä¾‹é€šè¿‡")
    
    if passed == len(results):
        print("ğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡ŒæˆåŠŸï¼")
        print("\nğŸ’¡ æç¤ºï¼š")
        print("   - å¹³è¡¡æ•°æ®é›†å·²ä¿å­˜åœ¨ example_balanced_datasets/")
        print("   - å…ƒæ•°æ®ä¿å­˜åœ¨ example_balanced_datasets/metadata/")
        print("   - å¯ä»¥åœ¨å®éªŒä¸­ä½¿ç”¨ BalancedCrossDomainDataManagerCore")
        print("   - æŸ¥çœ‹ README_balanced_datasets.md è·å–è¯¦ç»†æ–‡æ¡£")
        return True
    else:
        print("âš ï¸  éƒ¨åˆ†ç¤ºä¾‹è¿è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯ã€‚")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)