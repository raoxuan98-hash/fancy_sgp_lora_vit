#!/usr/bin/env python3
"""
åœ¨ subspace_lora.py ä¸­ä½¿ç”¨ä¿®æ”¹åçš„ get_incremental_subset æ–¹æ³•çš„ç¤ºä¾‹
"""

from utils.balanced_cross_domain_data_manager import create_balanced_data_manager

def demonstrate_usage():
    """
    æ¼”ç¤ºå¦‚ä½•åœ¨ subspace_lora.py ä¸­ä½¿ç”¨ get_incremental_subset æ–¹æ³•
    """
    print("=== æ¼”ç¤º subspace_lora.py ä¸­çš„ä½¿ç”¨æ–¹å¼ ===\n")
    
    # åˆ›å»ºå¹³è¡¡æ•°æ®ç®¡ç†å™¨ï¼ˆå¯ç”¨å¢é‡æ‹†åˆ†ï¼‰
    datasets = ['cifar100_224', 'cub200_224']
    
    manager = create_balanced_data_manager(
        dataset_names=datasets,
        balanced_datasets_root="balanced_datasets",
        use_balanced_datasets=True,
        enable_incremental_split=True,
        num_incremental_splits=3,
        incremental_split_seed=42
    )
    
    print(f"æ•°æ®ç®¡ç†å™¨åˆ›å»ºæˆåŠŸ:")
    print(f"  - æ€»ä»»åŠ¡æ•°: {manager.nb_tasks}")
    print(f"  - æ€»ç±»åˆ«æ•°: {manager.num_classes}")
    print(f"  - å¢é‡æ‹†åˆ†å¯ç”¨: {manager.enable_incremental_split}")
    
    # æ¨¡æ‹Ÿ subspace_lora.py ä¸­çš„è®­ç»ƒå¾ªç¯
    print(f"\nğŸ”„ æ¨¡æ‹Ÿ subspace_lora.py çš„è®­ç»ƒæµç¨‹:")
    
    for task_id in range(min(3, manager.nb_tasks)):  # æ¼”ç¤ºå‰3ä¸ªä»»åŠ¡
        print(f"\n--- ä»»åŠ¡ {task_id} ---")
        
        # ======= åŸæ¥çš„æ–¹å¼ (åœ¨ subspace_lora.py ç¬¬229-234è¡Œ) =======
        # train_set = data_manager.get_subset(
        #     task=task_id, source="train", cumulative=False, mode="train")
        # test_set = data_manager.get_subset(
        #     task=task_id, source="test", cumulative=True, mode="test")
        # train_set_test_mode = data_manager.get_subset(
        #     task=task_id, source="train", cumulative=False, mode="test")
        
        # ======= æ–°çš„æ–¹å¼ (ä½¿ç”¨ get_incremental_subset) =======
        train_set = manager.get_incremental_subset(
            task=task_id, source="train", cumulative=False, mode="train")
        test_set = manager.get_incremental_subset(
            task=task_id, source="test", cumulative=True, mode="test")
        train_set_test_mode = manager.get_incremental_subset(
            task=task_id, source="train", cumulative=False, mode="test")
        
        # æ˜¾ç¤ºç»“æœä¿¡æ¯
        print(f"  è®­ç»ƒé›† (cumulative=False): {len(train_set)} æ ·æœ¬")
        print(f"  æµ‹è¯•é›† (cumulative=True): {len(test_set)} æ ·æœ¬")
        print(f"  è®­ç»ƒé›†æµ‹è¯•æ¨¡å¼ (cumulative=False): {len(train_set_test_mode)} æ ·æœ¬")
        
        # éªŒè¯ç´¯ç§¯æ¨¡å¼çš„æ­£ç¡®æ€§
        if task_id > 0:
            expected_cumulative_size = sum(len(manager.datasets[i]['test_data']) for i in range(task_id + 1))
            if len(test_set) == expected_cumulative_size:
                print(f"  âœ… ç´¯ç§¯æ¨¡å¼éªŒè¯é€šè¿‡")
            else:
                print(f"  âŒ ç´¯ç§¯æ¨¡å¼éªŒè¯å¤±è´¥: æœŸæœ› {expected_cumulative_size}, å®é™… {len(test_set)}")
        
        # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
        print(f"  ğŸ‹ï¸  è®­ç»ƒæ¨¡å‹...")
        print(f"  ğŸ§ª è¯„ä¼°æ¨¡å‹...")
        
        # è·å–ä»»åŠ¡ä¿¡æ¯
        dataset_info = manager.datasets[task_id]
        print(f"  ğŸ“Š æ•°æ®é›†: {dataset_info['name']}")
        print(f"  ğŸ“š ç±»åˆ«æ•°: {dataset_info['num_classes']}")
        
        if task_id == 0:
            print(f"  â„¹ï¸  é¦–ä¸ªä»»åŠ¡ï¼Œä»…ä½¿ç”¨å½“å‰ä»»åŠ¡æ•°æ®")
        else:
            previous_classes = sum(manager.datasets[i]['num_classes'] for i in range(task_id))
            total_classes = previous_classes + dataset_info['num_classes']
            print(f"  â„¹ï¸  ç´¯ç§¯ {previous_classes} + {dataset_info['num_classes']} = {total_classes} ä¸ªç±»åˆ«")

def show_migration_guide():
    """
    å±•ç¤ºä» get_subset è¿ç§»åˆ° get_incremental_subset çš„æŒ‡å—
    """
    print(f"\n=== è¿ç§»æŒ‡å—ï¼šä» get_subset åˆ° get_incremental_subset ===\n")
    
    print("åœ¨ subspace_lora.py ä¸­è¿›è¡Œä»¥ä¸‹æ›¿æ¢:")
    print()
    
    print("1. åœ¨æ–‡ä»¶é¡¶éƒ¨æ·»åŠ æˆ–ç¡®è®¤å¯¼å…¥:")
    print("   from utils.balanced_cross_domain_data_manager import create_balanced_data_manager")
    print()
    
    print("2. æ›¿æ¢æ•°æ®ç®¡ç†å™¨çš„åˆ›å»º:")
    print("   # åŸæ¥çš„æ–¹å¼")
    print("   data_manager = CrossDomainDataManagerCore(dataset_names, ...)")
    print()
    print("   # æ–°çš„æ–¹å¼")
    print("   data_manager = create_balanced_data_manager(")
    print("       dataset_names=dataset_names,")
    print("       balanced_datasets_root='balanced_datasets',")
    print("       use_balanced_datasets=True,")
    print("       enable_incremental_split=True,  # å¯ç”¨å¢é‡æ‹†åˆ†")
    print("       num_incremental_splits=3,")
    print("       incremental_split_seed=42")
    print("   )")
    print()
    
    print("3. æ›¿æ¢ get_subset è°ƒç”¨ä¸º get_incremental_subset:")
    print("   # åŸæ¥çš„æ–¹å¼")
    print("   train_set = data_manager.get_subset(")
    print("       task=task_id, source='train', cumulative=False, mode='train')")
    print("   test_set = data_manager.get_subset(")
    print("       task=task_id, source='test', cumulative=True, mode='test')")
    print()
    print("   # æ–°çš„æ–¹å¼ (æ¨è)")
    print("   train_set = data_manager.get_incremental_subset(")
    print("       task=task_id, source='train', cumulative=False, mode='train')")
    print("   test_set = data_manager.get_incremental_subset(")
    print("       task=task_id, source='test', cumulative=True, mode='test')")
    print()
    
    print("4. å¥½å¤„:")
    print("   âœ… è¯­ä¹‰æ›´æ˜ç¡® - æ˜ç¡®è¡¨ç¤ºè¿™æ˜¯å¢é‡å­¦ä¹ åœºæ™¯")
    print("   âœ… å¢å¼ºçš„ç±»å‹å®‰å…¨æ€§ - ä¸“é—¨ä¸ºå¢é‡æ‹†åˆ†è®¾è®¡")
    print("   âœ… æ›´å¥½çš„é”™è¯¯å¤„ç† - å½“æœªå¯ç”¨å¢é‡æ‹†åˆ†æ—¶ä¼šæŠ›å‡ºæ˜ç¡®çš„é”™è¯¯")
    print("   âœ… ä¿æŒå‘åå…¼å®¹ - ä»ç„¶æ”¯æŒåŸæœ‰çš„å‚æ•°å’Œè¡Œä¸º")

def main():
    """ä¸»å‡½æ•°"""
    demonstrate_usage()
    show_migration_guide()
    
    print(f"\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼get_incremental_subset æ–¹æ³•ç°åœ¨å®Œå…¨æ”¯æŒ cumulative å‚æ•°")
    print(f"   å¯ä»¥æ— ç¼æ›¿æ¢ subspace_lora.py ä¸­çš„ get_subset è°ƒç”¨")

if __name__ == "__main__":
    main()