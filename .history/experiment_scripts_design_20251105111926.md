# å®éªŒè„šæœ¬è®¾è®¡æ–‡æ¡£

## 1. ä¸»å®éªŒè„šæœ¬è®¾è®¡

### 1.1 å®Œæ•´ä¸»å®éªŒè„šæœ¬ (run_main_experiments.sh)

```bash
#!/usr/bin/env bash
set -euo pipefail

echo "=========================================="
echo "Starting All Main Experiments"
echo "=========================================="

# åˆ›å»ºæ€»æ—¥å¿—ç›®å½•
MASTER_LOG_DIR="logs/main_experiments_$(date +%Y%m%d_%H%M%S)"
mkdir -p "$MASTER_LOG_DIR"

# æ•°æ®é›†åˆ—è¡¨
DATASETS=("cifar100_224" "imagenet-r" "cub200_224" "cars196_224")
SEEDS=(1993 1996 1997)
GPUS=(0 1 2 4)

# æ–¹æ³•é…ç½®
declare -A METHODS=(
    ["basic_lora"]="basic_lora 0.0"
    ["lora_kd"]="basic_lora 1.0"
    ["nsp_lora"]="nsp_lora 0.0"
    ["sgp_lora"]="sgp_lora 0.0"
)

# é¡ºåºæ‰§è¡Œæ‰€æœ‰æ–¹æ³•
for method in "${!METHODS[@]}"; do
    echo "=========================================="
    echo "Running ${method} Experiments"
    echo "=========================================="
    
    # è§£ææ–¹æ³•å‚æ•°
    params=(${METHODS[$method]})
    lora_type=${params[0]}
    gamma_kd=${params[1]}
    
    # åˆ›å»ºæ–¹æ³•ç‰¹å®šçš„æ—¥å¿—ç›®å½•
    METHOD_LOG_DIR="$MASTER_LOG_DIR/${method}"
    mkdir -p "$METHOD_LOG_DIR"
    
    # å¹¶è¡Œè¿è¡Œæ‰€æœ‰æ•°æ®é›†
    PIDS=()
    for i in "${!DATASETS[@]}"; do
        dataset="${DATASETS[$i]}"
        gpu="${GPUS[$((i % ${#GPUS[@]}))]}"
        
        # ä¸ºæ¯ä¸ªæ•°æ®é›†åˆ›å»ºå­è„šæœ¬
        cat > "$METHOD_LOG_DIR/run_${dataset}.sh" << EOF
#!/usr/bin/env bash
set -euo pipefail

DATASET="$dataset"
GPU="$gpu"
METHOD_LOG_DIR="$METHOD_LOG_DIR"
LORA_TYPE="$lora_type"
GAMMA_KD="$gamma_kd"
SEEDS=(${SEEDS[*]})

# æ–¹æ³•ç‰¹å®šå‚æ•°
case "$method" in
    "lora_kd")
        UPDATE_TEACHER_EACH_TASK=True
        DISTILLATION_TRANSFORM="identity"
        KD_TYPE="feat"
        ;;
    "nsp_lora")
        NSP_WEIGHT=0.05
        NSP_EPS=0.05
        ;;
    "sgp_lora")
        WEIGHT_TEMP=1.0
        WEIGHT_KIND="log1p"
        WEIGHT_P=2.0
        ;;
esac

for SEED in "\${SEEDS[@]}"; do
    echo "Running ${method} experiment: dataset=\$DATASET, seed=\$SEED, GPU=\$GPU"
    
    # æ„å»ºå‘½ä»¤
    CMD="CUDA_VISIBLE_DEVICES=\$GPU python -u main.py \\
        --dataset \"\$DATASET\" \\
        --smart_defaults \\
        --lora_type \"\$LORA_TYPE\" \\
        --vit_type \"vit-b-p16-mocov3\" \\
        --gamma_kd \"\$GAMMA_KD\" \\
        --seed_list \"\$SEED\""
    
    # æ·»åŠ æ–¹æ³•ç‰¹å®šå‚æ•°
    if [[ "$method" == "lora_kd" ]]; then
        CMD="$CMD \\
        --update_teacher_each_task \"\$UPDATE_TEACHER_EACH_TASK\" \\
        --distillation_transform \"\$DISTILLATION_TRANSFORM\" \\
        --kd_type \"\$KD_TYPE\""
    elif [[ "$method" == "nsp_lora" ]]; then
        CMD="$CMD \\
        --nsp_weight \"\$NSP_WEIGHT\" \\
        --nsp_eps \"\$NSP_EPS\""
    elif [[ "$method" == "sgp_lora" ]]; then
        CMD="$CMD \\
        --weight_temp \"\$WEIGHT_TEMP\" \\
        --weight_kind \"\$WEIGHT_KIND\" \\
        --weight_p \"\$WEIGHT_P\""
    fi
    
    # æ‰§è¡Œå‘½ä»¤å¹¶è®°å½•æ—¥å¿—
    eval \$CMD 2>&1 | tee "\$METHOD_LOG_DIR/\${DATASET}_seed\${SEED}.log"
done
EOF
        
        chmod +x "$METHOD_LOG_DIR/run_${dataset}.sh"
        
        # åœ¨åå°è¿è¡Œ
        echo "Starting ${method} experiments for $dataset on GPU $gpu"
        "$METHOD_LOG_DIR/run_${dataset}.sh" &
        PIDS+=($!)
    done
    
    # ç­‰å¾…æ‰€æœ‰æ•°æ®é›†å®Œæˆ
    echo "Waiting for ${method} experiments to complete..."
    for PID in "${PIDS[@]}"; do
        wait $PID
    done
    
    echo "${method} experiments completed."
done

echo "=========================================="
echo "All main experiments completed!"
echo "Logs saved to: $MASTER_LOG_DIR"
echo "=========================================="
```

### 1.2 å•ä¸ªæ–¹æ³•æ‰§è¡Œè„šæœ¬ (run_single_method.sh)

```bash
#!/usr/bin/env bash
set -euo pipefail

# å‚æ•°æ£€æŸ¥
if [ $# -ne 1 ]; then
    echo "Usage: $0 <method_name>"
    echo "Available methods: basic_lora, lora_kd, nsp_lora, sgp_lora"
    exit 1
fi

method=$1

# æ•°æ®é›†å’Œç§å­é…ç½®
DATASETS=("cifar100_224" "imagenet-r" "cub200_224" "cars196_224")
SEEDS=(1993 1996 1997)
GPUS=(0 1 2 4)

# åˆ›å»ºæ—¥å¿—ç›®å½•
LOG_DIR="logs/${method}_$(date +%Y%m%d_%H%M%S)"
mkdir -p "$LOG_DIR"

# æ–¹æ³•é…ç½®
case "$method" in
    "basic_lora")
        LORA_TYPE="basic_lora"
        GAMMA_KD=0.0
        ;;
    "lora_kd")
        LORA_TYPE="basic_lora"
        GAMMA_KD=1.0
        UPDATE_TEACHER_EACH_TASK=True
        DISTILLATION_TRANSFORM="identity"
        KD_TYPE="feat"
        ;;
    "nsp_lora")
        LORA_TYPE="nsp_lora"
        GAMMA_KD=0.0
        NSP_WEIGHT=0.05
        NSP_EPS=0.05
        ;;
    "sgp_lora")
        LORA_TYPE="sgp_lora"
        GAMMA_KD=0.0
        WEIGHT_TEMP=1.0
        WEIGHT_KIND="log1p"
        WEIGHT_P=2.0
        ;;
    *)
        echo "Unknown method: $method"
        exit 1
        ;;
esac

# å¹¶è¡Œè¿è¡Œæ‰€æœ‰æ•°æ®é›†
PIDS=()
for i in "${!DATASETS[@]}"; do
    dataset="${DATASETS[$i]}"
    gpu="${GPUS[$((i % ${#GPUS[@]}))]}"
    
    echo "Running ${method} experiment: dataset=$dataset, GPU=$gpu"
    
    # æ„å»ºå‘½ä»¤
    CMD="CUDA_VISIBLE_DEVICES=$gpu python -u main.py \\
        --dataset \"$dataset\" \\
        --smart_defaults \\
        --lora_type \"$LORA_TYPE\" \\
        --vit_type \"vit-b-p16-mocov3\" \\
        --gamma_kd \"$GAMMA_KD\" \\
        --seed_list \"${SEEDS[@]}\""
    
    # æ·»åŠ æ–¹æ³•ç‰¹å®šå‚æ•°
    if [[ "$method" == "lora_kd" ]]; then
        CMD="$CMD \\
        --update_teacher_each_task \"$UPDATE_TEACHER_EACH_TASK\" \\
        --distillation_transform \"$DISTILLATION_TRANSFORM\" \\
        --kd_type \"$KD_TYPE\""
    elif [[ "$method" == "nsp_lora" ]]; then
        CMD="$CMD \\
        --nsp_weight \"$NSP_WEIGHT\" \\
        --nsp_eps \"$NSP_EPS\""
    elif [[ "$method" == "sgp_lora" ]]; then
        CMD="$CMD \\
        --weight_temp \"$WEIGHT_TEMP\" \\
        --weight_kind \"$WEIGHT_KIND\" \\
        --weight_p \"$WEIGHT_P\""
    fi
    
    # æ‰§è¡Œå‘½ä»¤å¹¶è®°å½•æ—¥å¿—
    eval $CMD 2>&1 | tee "$LOG_DIR/${dataset}.log" &
    PIDS+=($!)
done

# ç­‰å¾…æ‰€æœ‰å®éªŒå®Œæˆ
echo "Waiting for all experiments to complete..."
for PID in "${PIDS[@]}"; do
    wait $PID
done

echo "${method} experiments completed. Logs saved to $LOG_DIR"
```

## 2. LoRA-SGPè¶…å‚æ•°ç½‘æ ¼æœç´¢è„šæœ¬

### 2.1 SGPå‚æ•°ç½‘æ ¼æœç´¢ (run_sgp_grid_search.sh)

```bash
#!/usr/bin/env bash
set -euo pipefail

# å‚æ•°é…ç½®
DATASET=${1:-"cifar100_224"}  # é»˜è®¤æ•°æ®é›†
GPU_LIST=${2:-"0,1,2,4"}      # é»˜è®¤GPUåˆ—è¡¨
IFS=',' read -r -a GPUS <<< "$GPU_LIST"

# è¶…å‚æ•°ç½‘æ ¼
WEIGHT_TEMPS=(1.0 2.0 4.0)
WEIGHT_PS=(1.0 2.0)
WEIGHT_KINDS=("log1p" "exp" "rational1")
SEEDS=(1993 1996 1997)

# å¹¶è¡Œæ§åˆ¶
MAX_PARALLEL=4  # æœ€å¤§å¹¶è¡Œæ•°

# åˆ›å»ºæ—¥å¿—ç›®å½•
LOG_DIR="logs/sgp_grid_${DATASET}_$(date +%Y%m%d_%H%M%S)"
mkdir -p "$LOG_DIR"

# å®éªŒè®¡æ•°å™¨
run_idx=0
jobs_running=0

echo "Starting SGP grid search on $DATASET"
echo "Parameter combinations: ${#WEIGHT_TEMPS[@]} Ã— ${#WEIGHT_PS[@]} Ã— ${#WEIGHT_KINDS[@]} Ã— ${#SEEDS[@]} = $((${#WEIGHT_TEMPS[@]} * ${#WEIGHT_PS[@]} * ${#WEIGHT_KINDS[@]} * ${#SEEDS[@]}))"

# éå†æ‰€æœ‰å‚æ•°ç»„åˆ
for temp in "${WEIGHT_TEMPS[@]}"; do
    for p in "${WEIGHT_PS[@]}"; do
        for kind in "${WEIGHT_KINDS[@]}"; do
            for seed in "${SEEDS[@]}"; do
                # GPUåˆ†é…
                gpu=${GPUS[$((run_idx % ${#GPUS[@]}))]}
                
                echo "[RUN $run_idx | GPU $gpu] dataset=$DATASET temp=$temp p=$p kind=$kind seed=$seed"
                
                # æ„å»ºå‘½ä»¤
                CMD="CUDA_VISIBLE_DEVICES=$gpu python -u main.py \\
                    --dataset \"$DATASET\" \\
                    --smart_defaults \\
                    --lora_type sgp_lora \\
                    --vit_type \"vit-b-p16-mocov3\" \\
                    --gamma_kd 0.0 \\
                    --weight_temp $temp \\
                    --weight_p $p \\
                    --weight_kind \"$kind\" \\
                    --seed_list $seed"
                
                # æ‰§è¡Œå‘½ä»¤
                eval $CMD > "$LOG_DIR/${DATASET}_temp${temp}_p${p}_kind${kind}_seed${seed}.log" 2>&1 &
                
                # æ›´æ–°è®¡æ•°å™¨
                run_idx=$((run_idx + 1))
                jobs_running=$((jobs_running + 1))
                
                # å¹¶è¡Œæ§åˆ¶
                if (( jobs_running >= MAX_PARALLEL )); then
                    wait  # ç­‰å¾…ä¸€ä¸ªä»»åŠ¡å®Œæˆ
                    jobs_running=$((jobs_running - 1))
                fi
            done
        done
    done
done

# ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
wait

echo "SGP grid search completed. Logs saved to $LOG_DIR"
echo "Total experiments run: $run_idx"
```

### 2.2 å¿«é€ŸSGPå‚æ•°æœç´¢ (run_sgp_quick_search.sh)

```bash
#!/usr/bin/env bash
set -euo pipefail

# å¿«é€Ÿæœç´¢é…ç½® - åªæµ‹è¯•æœ€æœ‰å¸Œæœ›çš„å‚æ•°ç»„åˆ
DATASET=${1:-"imagenet-r"}
GPU_LIST=${2:-"0,1,2,4"}
IFS=',' read -r -a GPUS <<< "$GPU_LIST"

# ç²¾ç®€çš„å‚æ•°ç»„åˆ
WEIGHT_TEMPS=(1.0 2.0)
WEIGHT_PS=(1.0 2.0)
WEIGHT_KINDS=("log1p")  # åªæµ‹è¯•log1p
SEEDS=(1993)  # åªç”¨ä¸€ä¸ªç§å­å¿«é€Ÿæµ‹è¯•

# å¹¶è¡Œæ§åˆ¶
MAX_PARALLEL=2

# åˆ›å»ºæ—¥å¿—ç›®å½•
LOG_DIR="logs/sgp_quick_${DATASET}_$(date +%Y%m%d_%H%M%S)"
mkdir -p "$LOG_DIR"

run_idx=0
jobs_running=0

echo "Starting quick SGP search on $DATASET"

for temp in "${WEIGHT_TEMPS[@]}"; do
    for p in "${WEIGHT_PS[@]}"; do
        for seed in "${SEEDS[@]}"; do
            gpu=${GPUS[$((run_idx % ${#GPUS[@]}))]}
            
            echo "[RUN $run_idx | GPU $gpu] dataset=$DATASET temp=$temp p=$p seed=$seed"
            
            CUDA_VISIBLE_DEVICES=$gpu python -u main.py \
                --dataset "$DATASET" \
                --smart_defaults \
                --lora_type sgp_lora \
                --vit_type "vit-b-p16-mocov3" \
                --gamma_kd 0.0 \
                --weight_temp $temp \
                --weight_p $p \
                --weight_kind "log1p" \
                --seed_list $seed \
                > "$LOG_DIR/${DATASET}_temp${temp}_p${p}_seed${seed}.log" 2>&1 &
            
            run_idx=$((run_idx + 1))
            jobs_running=$((jobs_running + 1))
            
            if (( jobs_running >= MAX_PARALLEL )); then
                wait
                jobs_running=$((jobs_running - 1))
            fi
        done
    done
done

wait

echo "Quick SGP search completed. Logs saved to $LOG_DIR"
```

## 3. æ¶ˆèç ”ç©¶è„šæœ¬

### 3.1 ç»„ä»¶æ¶ˆèå®éªŒ (run_component_ablation.sh)

```bash
#!/usr/bin/env bash
set -euo pipefail

# æ•°æ®é›†é…ç½®
DATASETS=("cifar100_224" "imagenet-r" "cub200_224" "cars196_224")
SEEDS=(1993 1996 1997)
GPUS=(0 1 2 4)

# æ¶ˆèé…ç½®
declare -A ABLATION_CONFIGS=(
    ["full_method"]="sgp_lora 0.0 1.0 log1p 2.0"
    ["wo_sgp"]="basic_lora 0.0"
    ["wo_amdc"]="sgp_lora 0.0 1.0 log1p 2.0 --no_amdc"
    ["wo_both"]="basic_lora 0.0 --no_amdc"
)

# åˆ›å»ºæ—¥å¿—ç›®å½•
LOG_DIR="logs/component_ablation_$(date +%Y%m%d_%H%M%S)"
mkdir -p "$LOG_DIR"

echo "Starting component ablation studies..."

for ablation_type in "${!ABLATION_CONFIGS[@]}"; do
    echo "=========================================="
    echo "Running ${ablation_type} experiments"
    echo "=========================================="
    
    # è§£æé…ç½®
    config=(${ABLATION_CONFIGS[$ablation_type]})
    lora_type=${config[0]}
    gamma_kd=${config[1]}
    
    # åˆ›å»ºæ¶ˆèç‰¹å®šçš„æ—¥å¿—ç›®å½•
    ABLATION_LOG_DIR="$LOG_DIR/${ablation_type}"
    mkdir -p "$ABLATION_LOG_DIR"
    
    # å¹¶è¡Œè¿è¡Œæ‰€æœ‰æ•°æ®é›†
    PIDS=()
    for i in "${!DATASETS[@]}"; do
        dataset="${DATASETS[$i]}"
        gpu="${GPUS[$((i % ${#GPUS[@]}))]}"
        
        echo "Running ${ablation_type} on $dataset (GPU $gpu)"
        
        # æ„å»ºå‘½ä»¤
        CMD="CUDA_VISIBLE_DEVICES=$gpu python -u main.py \\
            --dataset \"$dataset\" \\
            --smart_defaults \\
            --lora_type \"$lora_type\" \\
            --vit_type \"vit-b-p16-mocov3\" \\
            --gamma_kd \"$gamma_kd\" \\
            --seed_list \"${SEEDS[@]}\""
        
        # æ·»åŠ SGPç‰¹å®šå‚æ•°
        if [[ "$lora_type" == "sgp_lora" ]]; then
            weight_temp=${config[2]}
            weight_kind=${config[3]}
            weight_p=${config[4]}
            CMD="$CMD \\
                --weight_temp $weight_temp \\
                --weight_kind \"$weight_kind\" \\
                --weight_p $weight_p"
        fi
        
        # æ·»åŠ AMDCæ§åˆ¶å‚æ•°
        if [[ " ${config[*]} " =~ " --no_amdc " ]]; then
            CMD="$CMD --no_amdc"
        fi
        
        # æ‰§è¡Œå‘½ä»¤
        eval $CMD > "$ABLATION_LOG_DIR/${dataset}.log" 2>&1 &
        PIDS+=($!)
    done
    
    # ç­‰å¾…æ‰€æœ‰æ•°æ®é›†å®Œæˆ
    for PID in "${PIDS[@]}"; do
        wait $PID
    done
    
    echo "${ablation_type} experiments completed."
done

echo "All component ablation experiments completed. Logs saved to $LOG_DIR"
```

### 3.2 AMDCæ¶ˆèå®éªŒ (run_amdc_ablation.sh)

```bash
#!/usr/bin/env bash
set -euo pipefail

# æ•°æ®é›†é…ç½® - åªé€‰æ‹©ä¸¤ä¸ªä»£è¡¨æ€§æ•°æ®é›†
DATASETS=("imagenet-r" "cars196_224")
SEEDS=(1993 1996 1997)
GPUS=(0 1 2 4)

# AMDCæ¶ˆèé…ç½®
declare -A AMDC_CONFIGS=(
    ["full_amdc"]="attention_transform"
    ["mean_only"]="mean_only"
    ["cov_only"]="cov_only"
    ["linear_transform"]="linear_transform"
    ["weaknonlinear_transform"]="weaknonlinear_transform"
)

# åˆ›å»ºæ—¥å¿—ç›®å½•
LOG_DIR="logs/amdc_ablation_$(date +%Y%m%d_%H%M%S)"
mkdir -p "$LOG_DIR"

echo "Starting AMDC ablation studies..."

for amdc_type in "${!AMDC_CONFIGS[@]}"; do
    echo "=========================================="
    echo "Running ${amdc_type} experiments"
    echo "=========================================="
    
    transform_type=${AMDC_CONFIGS[$amdc_type]}
    
    # åˆ›å»ºAMDCç‰¹å®šçš„æ—¥å¿—ç›®å½•
    AMDC_LOG_DIR="$LOG_DIR/${amdc_type}"
    mkdir -p "$AMDC_LOG_DIR"
    
    # å¹¶è¡Œè¿è¡Œæ‰€æœ‰æ•°æ®é›†
    PIDS=()
    for i in "${!DATASETS[@]}"; do
        dataset="${DATASETS[$i]}"
        gpu="${GPUS[$((i % ${#GPUS[@]}))]}"
        
        echo "Running ${amdc_type} on $dataset (GPU $gpu)"
        
        # æ„å»ºå‘½ä»¤
        CMD="CUDA_VISIBLE_DEVICES=$gpu python -u main.py \\
            --dataset \"$dataset\" \\
            --smart_defaults \\
            --lora_type sgp_lora \\
            --vit_type \"vit-b-p16-mocov3\" \\
            --gamma_kd 0.0 \\
            --weight_temp 1.0 \\
            --weight_kind \"log1p\" \\
            --weight_p 2.0 \\
            --seed_list \"${SEEDS[@]}\""
        
        # æ·»åŠ AMDCç‰¹å®šå‚æ•°
        if [[ "$amdc_type" != "full_amdc" ]]; then
            CMD="$CMD --amdc_type \"$transform_type\""
        fi
        
        # æ‰§è¡Œå‘½ä»¤
        eval $CMD > "$AMDC_LOG_DIR/${dataset}.log" 2>&1 &
        PIDS+=($!)
    done
    
    # ç­‰å¾…æ‰€æœ‰æ•°æ®é›†å®Œæˆ
    for PID in "${PIDS[@]}"; do
        wait $PID
    done
    
    echo "${amdc_type} experiments completed."
done

echo "All AMDC ablation experiments completed. Logs saved to $LOG_DIR"
```

## 4. è¡¥å……å®éªŒè„šæœ¬

### 4.1 é•¿åºåˆ—ä»»åŠ¡å®éªŒ (run_long_sequence.sh)

```bash
#!/usr/bin/env bash
set -euo pipefail

# é•¿åºåˆ—é…ç½®
DATASET="cifar100_224"
INIT_CLS=5
INCREMENT=5  # æ¯ä»»åŠ¡5ç±»ï¼Œå…±20ä¸ªä»»åŠ¡
SEEDS=(1993 1996 1997)
GPUS=(0 1 2 4)

# æ–¹æ³•é…ç½®
declare -A METHODS=(
    ["basic_lora"]="basic_lora"
    ["lora_kd"]="basic_lora"
    ["nsp_lora"]="nsp_lora"
    ["sgp_lora"]="sgp_lora"
)

# åˆ›å»ºæ—¥å¿—ç›®å½•
LOG_DIR="logs/long_sequence_$(date +%Y%m%d_%H%M%S)"
mkdir -p "$LOG_DIR"

echo "Starting long sequence experiments (20 tasks Ã— 5 classes)..."

for method in "${!METHODS[@]}"; do
    echo "=========================================="
    echo "Running ${method} long sequence experiments"
    echo "=========================================="
    
    lora_type=${METHODS[$method]}
    
    # åˆ›å»ºæ–¹æ³•ç‰¹å®šçš„æ—¥å¿—ç›®å½•
    METHOD_LOG_DIR="$LOG_DIR/${method}"
    mkdir -p "$METHOD_LOG_DIR"
    
    # å¹¶è¡Œè¿è¡Œæ‰€æœ‰ç§å­
    PIDS=()
    for i in "${!SEEDS[@]}"; do
        seed=${SEEDS[$i]}
        gpu=${GPUS[$((i % ${#GPUS[@]}))]}
        
        echo "Running ${method} long sequence: seed=$seed, GPU=$gpu"
        
        # æ„å»ºå‘½ä»¤
        CMD="CUDA_VISIBLE_DEVICES=$gpu python -u main.py \\
            --dataset \"$DATASET\" \\
            --init_cls $INIT_CLS \\
            --increment $INCREMENT \\
            --lora_type \"$lora_type\" \\
            --vit_type \"vit-b-p16-mocov3\" \\
            --gamma_kd 0.0 \\
            --seed_list $seed"
        
        # æ·»åŠ æ–¹æ³•ç‰¹å®šå‚æ•°
        if [[ "$method" == "lora_kd" ]]; then
            CMD="$CMD \\
                --gamma_kd 1.0 \\
                --update_teacher_each_task True \\
                --distillation_transform identity \\
                --kd_type feat"
        elif [[ "$method" == "nsp_lora" ]]; then
            CMD="$CMD \\
                --nsp_weight 0.05 \\
                --nsp_eps 0.05"
        elif [[ "$method" == "sgp_lora" ]]; then
            CMD="$CMD \\
                --weight_temp 1.0 \\
                --weight_kind \"log1p\" \\
                --weight_p 2.0"
        fi
        
        # æ‰§è¡Œå‘½ä»¤
        eval $CMD > "$METHOD_LOG_DIR/seed${seed}.log" 2>&1 &
        PIDS+=($!)
    done
    
    # ç­‰å¾…æ‰€æœ‰ç§å­å®Œæˆ
    for PID in "${PIDS[@]}"; do
        wait $PID
    done
    
    echo "${method} long sequence experiments completed."
done

echo "All long sequence experiments completed. Logs saved to $LOG_DIR"
```

### 4.2 è·¨æ¶æ„æ³›åŒ–å®éªŒ (run_cross_architecture.sh)

```bash
#!/usr/bin/env bash
set -euo pipefail

# è·¨æ¶æ„é…ç½®
DATASETS=("cifar100_224" "imagenet-r" "cub200_224" "cars196_224")
SEEDS=(1993 1996 1997)
GPUS=(0 1 2 4)

# ViTæ¶æ„åˆ—è¡¨
VIT_TYPES=("vit-b-p16-mocov3" "vit-b-p16" "vit-b-p-clip")

# åˆ›å»ºæ—¥å¿—ç›®å½•
LOG_DIR="logs/cross_architecture_$(date +%Y%m%d_%H%M%S)"
mkdir -p "$LOG_DIR"

echo "Starting cross-architecture experiments..."

for vit_type in "${VIT_TYPES[@]}"; do
    echo "=========================================="
    echo "Running experiments with ${vit_type}"
    echo "=========================================="
    
    # åˆ›å»ºæ¶æ„ç‰¹å®šçš„æ—¥å¿—ç›®å½•
    ARCH_LOG_DIR="$LOG_DIR/${vit_type}"
    mkdir -p "$ARCH_LOG_DIR"
    
    # å¹¶è¡Œè¿è¡Œæ‰€æœ‰æ•°æ®é›†
    PIDS=()
    for i in "${!DATASETS[@]}"; do
        dataset="${DATASETS[$i]}"
        gpu="${GPUS[$((i % ${#GPUS[@]}))]}"
        
        echo "Running SGP on $dataset with ${vit_type} (GPU $gpu)"
        
        # æ„å»ºå‘½ä»¤
        CMD="CUDA_VISIBLE_DEVICES=$gpu python -u main.py \\
            --dataset \"$dataset\" \\
            --smart_defaults \\
            --lora_type sgp_lora \\
            --vit_type \"$vit_type\" \\
            --gamma_kd 0.0 \\
            --weight_temp 1.0 \\
            --weight_kind \"log1p\" \\
            --weight_p 2.0 \\
            --seed_list \"${SEEDS[@]}\""
        
        # æ‰§è¡Œå‘½ä»¤
        eval $CMD > "$ARCH_LOG_DIR/${dataset}.log" 2>&1 &
        PIDS+=($!)
    done
    
    # ç­‰å¾…æ‰€æœ‰æ•°æ®é›†å®Œæˆ
    for PID in "${PIDS[@]}"; do
        wait $PID
    done
    
    echo "${vit_type} experiments completed."
done

echo "All cross-architecture experiments completed. Logs saved to $LOG_DIR"
```

## 5. ç»“æœæ”¶é›†å’Œåˆ†æè„šæœ¬

### 5.1 ç»“æœæ”¶é›†è„šæœ¬ (collect_results.py)

```python
#!/usr/bin/env python3
import os
import json
import glob
import argparse
from pathlib import Path
import pandas as pd
import numpy as np

def find_aggregate_files(log_dir):
    """æŸ¥æ‰¾æ‰€æœ‰aggregate_results.jsonæ–‡ä»¶"""
    pattern = os.path.join(log_dir, "**", "aggregate_results.json")
    return glob.glob(pattern, recursive=True)

def parse_aggregate_file(file_path):
    """è§£æå•ä¸ªaggregate_results.jsonæ–‡ä»¶"""
    with open(file_path, 'r') as f:
        data = json.load(f)
    
    # ä»è·¯å¾„ä¸­æå–å®éªŒä¿¡æ¯
    path_parts = Path(file_path).parts
    
    # æå–æ•°æ®é›†ã€æ–¹æ³•ã€ç§å­ç­‰ä¿¡æ¯
    dataset = None
    method = None
    seed = None
    vit_type = None
    
    for part in path_parts:
        if part.endswith('_224'):
            dataset = part
        elif part in ['basic_lora', 'lora_kd', 'nsp_lora', 'sgp_lora']:
            method = part
        elif part.startswith('vit-'):
            vit_type = part
    
    # å°è¯•ä»æ–‡ä»¶åæˆ–ç›®å½•åä¸­æå–ç§å­
    for part in reversed(path_parts):
        if part.isdigit() and len(part) == 4:  # ç§å­é€šå¸¸æ˜¯4ä½æ•°
            seed = int(part)
            break
    
    # æå–ç»“æœ
    results = {}
    if 'final_task_stats' in data:
        for variant, stats in data['final_task_stats'].items():
            results[f"{variant}_last"] = stats['mean']
    
    if 'average_across_tasks_stats' in data:
        for variant, stats in data['average_across_tasks_stats'].items():
            results[f"{variant}_avg"] = stats['mean']
    
    return {
        'dataset': dataset,
        'method': method,
        'seed': seed,
        'vit_type': vit_type,
        'file_path': file_path,
        **results
    }

def collect_all_results(log_dir):
    """æ”¶é›†æ‰€æœ‰å®éªŒç»“æœ"""
    aggregate_files = find_aggregate_files(log_dir)
    print(f"Found {len(aggregate_files)} aggregate result files")
    
    all_results = []
    for file_path in aggregate_files:
        try:
            result = parse_aggregate_file(file_path)
            all_results.append(result)
        except Exception as e:
            print(f"Error parsing {file_path}: {e}")
    
    return all_results

def create_results_dataframe(results):
    """åˆ›å»ºç»“æœDataFrame"""
    df = pd.DataFrame(results)
    
    # å¦‚æœæœ‰ç§å­åˆ—ï¼Œè®¡ç®—å¹³å‡å€¼å’Œæ ‡å‡†å·®
    if 'seed' in df.columns:
        # æŒ‰æ•°æ®é›†ã€æ–¹æ³•ã€vit_typeåˆ†ç»„è®¡ç®—ç»Ÿè®¡é‡
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        numeric_cols = [col for col in numeric_cols if col not in ['seed']]
        
        summary_stats = []
        
        for (dataset, method, vit_type), group in df.groupby(['dataset', 'method', 'vit_type']):
            row = {
                'dataset': dataset,
                'method': method,
                'vit_type': vit_type,
                'num_seeds': len(group)
            }
            
            for col in numeric_cols:
                if col in group.columns:
                    row[f"{col}_mean"] = group[col].mean()
                    row[f"{col}_std"] = group[col].std()
            
            summary_stats.append(row)
        
        summary_df = pd.DataFrame(summary_stats)
        return df, summary_df
    
    return df, None

def main():
    parser = argparse.ArgumentParser(description='Collect experiment results')
    parser.add_argument('--log_dir', type=str, required=True, 
                       help='Directory containing experiment logs')
    parser.add_argument('--output', type=str, default='results',
                       help='Output directory for results')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output, exist_ok=True)
    
    # æ”¶é›†ç»“æœ
    results = collect_all_results(args.log_dir)
    
    if not results:
        print("No results found!")
        return
    
    # åˆ›å»ºDataFrame
    df, summary_df = create_results_dataframe(results)
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    detailed_file = os.path.join(args.output, 'detailed_results.csv')
    df.to_csv(detailed_file, index=False)
    print(f"Detailed results saved to {detailed_file}")
    
    # ä¿å­˜æ±‡æ€»ç»“æœ
    if summary_df is not None:
        summary_file = os.path.join(args.output, 'summary_results.csv')
        summary_df.to_csv(summary_file, index=False)
        print(f"Summary results saved to {summary_file}")
    
    # ä¿å­˜åŸå§‹JSONç»“æœ
    json_file = os.path.join(args.output, 'all_results.json')
    with open(json_file, 'w') as f:
        json.dump(results, f, indent=2)
    print(f"Raw results saved to {json_file}")

if __name__ == '__main__':
    main()
```

### 5.2 ç»“æœè¡¨æ ¼ç”Ÿæˆè„šæœ¬ (generate_tables.py)

```python
#!/usr/bin/env python3
import os
import pandas as pd
import argparse
from tabulate import tabulate

def load_results(csv_file):
    """åŠ è½½ç»“æœCSVæ–‡ä»¶"""
    return pd.read_csv(csv_file)

def format_mean_std(mean, std):
    """æ ¼å¼åŒ–å¹³å‡å€¼Â±æ ‡å‡†å·®"""
    return f"{mean:.2f}Â±{std:.2f}"

def create_main_results_table(df):
    """åˆ›å»ºä¸»å®éªŒç»“æœè¡¨æ ¼"""
    # ç­›é€‰ä¸»è¦ç»“æœå˜ä½“
    main_variants = [
        'SeqFT + attention_transform + LDA',
        'SeqFT + attention_transform + QDA'
    ]
    
    # åˆ›å»ºç»“æœè¡¨æ ¼
    table_data = []
    
    for dataset in df['dataset'].unique():
        row = {'Dataset': dataset}
        
        for method in df['method'].unique():
            method_df = df[(df['dataset'] == dataset) & (df['method'] == method)]
            
            if len(method_df) == 0:
                continue
            
            # è·å–æœ€ä½³ç»“æœ
            for variant in main_variants:
                last_col = f"{variant}_last_mean"
                avg_col = f"{variant}_avg_mean"
                last_std_col = f"{variant}_last_std"
                avg_std_col = f"{variant}_avg_std"
                
                if last_col in method_df.columns and avg_col in method_df.columns:
                    last_acc = method_df[last_col].iloc[0]
                    avg_acc = method_df[avg_col].iloc[0]
                    last_std = method_df[last_std_col].iloc[0]
                    avg_std = method_df[avg_std_col].iloc[0]
                    
                    method_name = f"{method}_{variant.split(' + ')[-1]}"
                    row[f"{method_name}_last"] = format_mean_std(last_acc, last_std)
                    row[f"{method_name}_avg"] = format_mean_std(avg_acc, avg_std)
                    break  # åªå–ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„å˜ä½“
        
        table_data.append(row)
    
    return pd.DataFrame(table_data)

def create_ablation_table(df, ablation_type):
    """åˆ›å»ºæ¶ˆèå®éªŒè¡¨æ ¼"""
    # æ ¹æ®æ¶ˆèç±»å‹ç­›é€‰æ•°æ®
    if ablation_type == 'component':
        methods = ['full_method', 'wo_sgp', 'wo_amdc', 'wo_both']
    elif ablation_type == 'sgp':
        # éœ€è¦ä»å‚æ•°ä¸­æå–ä¸åŒçš„SGPé…ç½®
        pass
    elif ablation_type == 'amdc':
        # éœ€è¦ä»å‚æ•°ä¸­æå–ä¸åŒçš„AMDCé…ç½®
        pass
    
    table_data = []
    
    for dataset in df['dataset'].unique():
        row = {'Dataset': dataset}
        
        for method in methods:
            method_df = df[(df['dataset'] == dataset) & (df['method'] == method)]
            
            if len(method_df) == 0:
                continue
            
            # è·å–æœ€ä½³ç»“æœ
            best_variant = None
            best_acc = 0
            
            for col in method_df.columns:
                if col.endswith('_last_mean'):
                    acc = method_df[col].iloc[0]
                    if acc > best_acc:
                        best_acc = acc
                        best_variant = col.replace('_last_mean', '')
            
            if best_variant:
                last_mean = method_df[f"{best_variant}_last_mean"].iloc[0]
                last_std = method_df[f"{best_variant}_last_std"].iloc[0]
                avg_mean = method_df[f"{best_variant}_avg_mean"].iloc[0]
                avg_std = method_df[f"{best_variant}_avg_std"].iloc[0]
                
                row[f"{method}_last"] = format_mean_std(last_mean, last_std)
                row[f"{method}_avg"] = format_mean_std(avg_mean, avg_std)
        
        table_data.append(row)
    
    return pd.DataFrame(table_data)

def main():
    parser = argparse.ArgumentParser(description='Generate result tables')
    parser.add_argument('--results_csv', type=str, required=True,
                       help='CSV file with experiment results')
    parser.add_argument('--output_dir', type=str, default='tables',
                       help='Output directory for tables')
    parser.add_argument('--format', type=str, default='latex',
                       choices=['latex', 'markdown', 'grid'],
                       help='Output format')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # åŠ è½½ç»“æœ
    df = load_results(args.results_csv)
    
    # ç”Ÿæˆä¸»å®éªŒè¡¨æ ¼
    main_table = create_main_results_table(df)
    main_file = os.path.join(args.output_dir, f'main_results.{args.format}')
    
    if args.format == 'latex':
        with open(main_file, 'w') as f:
            f.write(main_table.to_latex(index=False, escape=False))
    elif args.format == 'markdown':
        with open(main_file, 'w') as f:
            f.write(main_table.to_markdown(index=False))
    else:
        with open(main_file, 'w') as f:
            f.write(tabulate(main_table, headers='keys', tablefmt='grid'))
    
    print(f"Main results table saved to {main_file}")
    
    # ç”Ÿæˆæ¶ˆèå®éªŒè¡¨æ ¼
    for ablation_type in ['component']:
        ablation_table = create_ablation_table(df, ablation_type)
        ablation_file = os.path.join(args.output_dir, f'{ablation_type}_ablation.{args.format}')
        
        if args.format == 'latex':
            with open(ablation_file, 'w') as f:
                f.write(ablation_table.to_latex(index=False, escape=False))
        elif args.format == 'markdown':
            with open(ablation_file, 'w') as f:
                f.write(ablation_table.to_markdown(index=False))
        else:
            with open(ablation_file, 'w') as f:
                f.write(tabulate(ablation_table, headers='keys', tablefmt='grid'))
        
        print(f"{ablation_type} ablation table saved to {ablation_file}")

if __name__ == '__main__':
    main()
```

## 6. å®éªŒæ‰§è¡Œæµç¨‹ä¼˜åŒ–

### 6.1 å®éªŒç®¡ç†å™¨ (experiment_manager.py)

```python
#!/usr/bin/env python3
import os
import json
import time
import subprocess
import argparse
from pathlib import Path
from typing import List, Dict, Optional

class ExperimentManager:
    def __init__(self, config_file: str):
        self.config = self.load_config(config_file)
        self.experiment_dir = Path(self.config.get('experiment_dir', 'experiments'))
        self.experiment_dir.mkdir(exist_ok=True)
        
    def load_config(self, config_file: str) -> Dict:
        """åŠ è½½å®éªŒé…ç½®"""
        with open(config_file, 'r') as f:
            return json.load(f)
    
    def run_experiment(self, experiment_config: Dict) -> bool:
        """è¿è¡Œå•ä¸ªå®éªŒ"""
        cmd = experiment_config['command']
        log_file = experiment_config['log_file']
        gpu = experiment_config.get('gpu', 0)
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        env = os.environ.copy()
        env['CUDA_VISIBLE_DEVICES'] = str(gpu)
        
        try:
            # åˆ›å»ºæ—¥å¿—ç›®å½•
            os.makedirs(os.path.dirname(log_file), exist_ok=True)
            
            # è¿è¡Œå®éªŒ
            with open(log_file, 'w') as f:
                process = subprocess.Popen(
                    cmd, shell=True, env=env, stdout=f, stderr=subprocess.STDOUT
                )
                
                # ç­‰å¾…è¿›ç¨‹å®Œæˆ
                return_code = process.wait()
                
                if return_code == 0:
                    print(f"âœ… Experiment completed: {log_file}")
                    return True
                else:
                    print(f"âŒ Experiment failed: {log_file} (return code: {return_code})")
                    return False
                    
        except Exception as e:
            print(f"âŒ Error running experiment: {e}")
            return False
    
    def run_experiments_parallel(self, experiments: List[Dict], max_parallel: int = 4):
        """å¹¶è¡Œè¿è¡Œå¤šä¸ªå®éªŒ"""
        running = []
        completed = []
        failed = []
        
        for exp in experiments:
            # ç­‰å¾…æœ‰ç©ºé—²æ§½ä½
            while len(running) >= max_parallel:
                # æ£€æŸ¥è¿è¡Œä¸­çš„å®éªŒ
                for i, (process, exp_config) in enumerate(running):
                    if process.poll() is not None:
                        running.pop(i)
                        if process.returncode == 0:
                            completed.append(exp_config)
                        else:
                            failed.append(exp_config)
                        break
                else:
                    time.sleep(10)  # ç­‰å¾…10ç§’åå†æ£€æŸ¥
            
            # å¯åŠ¨æ–°å®éªŒ
            cmd = exp['command']
            log_file = exp['log_file']
            gpu = exp.get('gpu', 0)
            
            # è®¾ç½®ç¯å¢ƒå˜é‡
            env = os.environ.copy()
            env['CUDA_VISIBLE_DEVICES'] = str(gpu)
            
            try:
                # åˆ›å»ºæ—¥å¿—ç›®å½•
                os.makedirs(os.path.dirname(log_file), exist_ok=True)
                
                # å¯åŠ¨è¿›ç¨‹
                with open(log_file, 'w') as f:
                    process = subprocess.Popen(
                        cmd, shell=True, env=env, stdout=f, stderr=subprocess.STDOUT
                    )
                
                running.append((process, exp))
                print(f"ğŸš€ Started experiment: {exp['name']}")
                
            except Exception as e:
                print(f"âŒ Failed to start experiment: {e}")
                failed.append(exp)
        
        # ç­‰å¾…æ‰€æœ‰å®éªŒå®Œæˆ
        for process, exp_config in running:
            process.wait()
            if process.returncode == 0:
                completed.append(exp_config)
            else:
                failed.append(exp_config)
        
        return completed, failed
    
    def generate_experiment_configs(self) -> List[Dict]:
        """æ ¹æ®é…ç½®ç”Ÿæˆå®éªŒåˆ—è¡¨"""
        experiments = []
        
        for exp_name, exp_config in self.config.get('experiments', {}).items():
            # æ•°æ®é›†å¾ªç¯
            for dataset in exp_config.get('datasets', []):
                # ç§å­å¾ªç¯
                for seed in exp_config.get('seeds', []):
                    # GPUåˆ†é…
                    gpu_idx = experiments % len(exp_config.get('gpus', [0]))
                    gpu = exp_config['gpus'][gpu_idx]
                    
                    # æ„å»ºå‘½ä»¤
                    cmd = f"python main.py --dataset {dataset} --seed_list {seed}"
                    
                    # æ·»åŠ å…¶ä»–å‚æ•°
                    for key, value in exp_config.get('parameters', {}).items():
                        if isinstance(value, bool):
                            if value:
                                cmd += f" --{key}"
                        else:
                            cmd += f" --{key} {value}"
                    
                    # åˆ›å»ºå®éªŒé…ç½®
                    exp = {
                        'name': f"{exp_name}_{dataset}_seed{seed}",
                        'command': cmd,
                        'log_file': str(self.experiment_dir / exp_name / f"{dataset}_seed{seed}.log"),
                        'gpu': gpu,
                        'dataset': dataset,
                        'seed': seed
                    }
                    
                    experiments.append(exp)
        
        return experiments

def main():
    parser = argparse.ArgumentParser(description='Experiment Manager')
    parser.add_argument('--config', type=str, required=True,
                       help='Experiment configuration file')
    parser.add_argument('--max_parallel', type=int, default=4,
                       help='Maximum parallel experiments')
    
    args = parser.parse_args()
    
    # åˆ›å»ºå®éªŒç®¡ç†å™¨
    manager = ExperimentManager(args.config)
    
    # ç”Ÿæˆå®éªŒé…ç½®
    experiments = manager.generate_experiment_configs()
    print(f"Generated {len(experiments)} experiments")
    
    # è¿è¡Œå®éªŒ
    completed, failed = manager.run_experiments_parallel(experiments, args.max_parallel)
    
    # è¾“å‡ºç»“æœ
    print(f"\nâœ… Completed experiments: {len(completed)}")
    print(f"âŒ Failed experiments: {len(failed)}")
    
    if failed:
        print("\nFailed experiments:")
        for exp in failed:
            print(f"  - {exp['name']}: {exp['log_file']}")

if __name__ == '__main__':
    main()
```

### 6.2 å®éªŒé…ç½®ç¤ºä¾‹ (experiment_config.json)

```json
{
  "experiment_dir": "experiments",
  "experiments": {
    "main_experiments": {
      "datasets": ["cifar100_224", "imagenet-r", "cub200_224", "cars196_224"],
      "seeds": [1993, 1996, 1997],
      "gpus": [0, 1, 2, 4],
      "parameters": {
        "smart_defaults": true,
        "lora_type": "sgp_lora",
        "vit_type": "vit-b-p16-mocov3",
        "gamma_kd": 0.0,
        "weight_temp": 1.0,
        "weight_kind": "log1p",
        "weight_p": 2.0
      }
    },
    "ablation_studies": {
      "datasets": ["cifar100_224", "imagenet-r"],
      "seeds": [1993, 1996, 1997],
      "gpus": [0, 1, 2, 4],
      "variants": [
        {
          "name": "full_method",
          "parameters": {
            "lora_type": "sgp_lora",
            "gamma_kd": 0.0,
            "weight_temp": 1.0,
            "weight_kind": "log1p",
            "weight_p": 2.0
          }
        },
        {
          "name": "wo_sgp",
          "parameters": {
            "lora_type": "basic_lora",
            "gamma_kd": 0.0
          }
        }
      ]
    }
  }
}
```

è¿™ä¸ªå®éªŒè„šæœ¬è®¾è®¡æä¾›äº†ï¼š

1. **å®Œæ•´çš„ä¸»å®éªŒè„šæœ¬**ï¼šæ”¯æŒ4ç§å¯¹æ¯”æ–¹æ³•åœ¨4ä¸ªæ•°æ®é›†ä¸Šçš„å¹¶è¡Œæ‰§è¡Œ
2. **è¶…å‚æ•°ç½‘æ ¼æœç´¢**ï¼šæ”¯æŒSGPå‚æ•°çš„ç³»ç»Ÿæ€§æœç´¢
3. **æ¶ˆèç ”ç©¶è„šæœ¬**ï¼šæ”¯æŒç»„ä»¶æ¶ˆèã€SGPæ¶ˆèå’ŒAMDCæ¶ˆè
4. **è¡¥å……å®éªŒè„šæœ¬**ï¼šæ”¯æŒé•¿åºåˆ—ä»»åŠ¡å’Œè·¨æ¶æ„æ³›åŒ–å®éªŒ
5. **ç»“æœæ”¶é›†å’Œåˆ†æ**ï¼šè‡ªåŠ¨åŒ–ç»“æœæ”¶é›†å’Œè¡¨æ ¼ç”Ÿæˆ
6. **å®éªŒç®¡ç†å™¨**ï¼šæä¾›å¹¶è¡Œæ‰§è¡Œå’Œèµ„æºç®¡ç†åŠŸèƒ½

æ‰€æœ‰è„šæœ¬éƒ½è€ƒè™‘äº†GPUèµ„æºåˆ†é…ã€å¹¶è¡Œæ‰§è¡Œã€æ—¥å¿—è®°å½•å’Œé”™è¯¯å¤„ç†ï¼Œç¡®ä¿å®éªŒèƒ½å¤Ÿé«˜æ•ˆå¯é åœ°è¿è¡Œã€‚