#!/usr/bin/env python3
"""
æµ‹è¯•è„šæœ¬ï¼šéªŒè¯å¤šä¸ªéšæœºç§å­çš„ç»“æœèšåˆæ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys
import json
import shutil
from pathlib import Path

def test_aggregation():
    """æµ‹è¯•èšåˆé€»è¾‘"""
    
    # æ¨¡æ‹Ÿå‚æ•°
    test_args = {
        'model_name': 'sldc',
        'user': 'test_user',
        'dataset': 'cifar100_224',
        'vit_type': 'vit-b-p16-mocov3',
        'init_cls': 10,
        'increment': 10,
        'lora_rank': 4,
        'lora_type': 'sgp_lora',
        'weight_temp': 2.0,
        'weight_kind': 'log1p',
        'weight_p': 1.0,
        'optimizer': 'adamw',
        'lrate': 0.0001,
        'batch_size': 16,
        'iterations': 50,  # å‡å°‘è¿­ä»£æ¬¡æ•°ä»¥åŠ å¿«æµ‹è¯•
        'gamma_kd': 0.0,
        'seed_list': [1993, 1996],  # åªç”¨ä¸¤ä¸ªç§å­è¿›è¡Œæµ‹è¯•
        'smart_defaults': False,
        'shuffle': True,
        'memory_size': 0,
        'memory_per_class': 0,
        'fixed_memory': False,
        'warmup_ratio': 0.1,
        'ca_epochs': 5,
        'evaluate_final_only': True,
        'update_teacher_each_task': True,
        'use_aux_for_kd': False,
        'kd_type': 'feat',
        'distillation_transform': 'linear',
        'eval_only': False,
        'lda_reg_alpha': 0.10,
        'qda_reg_alpha1': 0.20,
        'qda_reg_alpha2': 0.90,
        'qda_reg_alpha3': 0.20,
        'auxiliary_data_path': '/data1/open_datasets',
        'aux_dataset': 'imagenet',
        'auxiliary_data_size': 1024,
        'l2_protection': False,
        'l2_protection_lambda': 1e-4,
        'weight_decay': 3e-5,
        'head_scale': 1.0
    }
    
    # æ¸…ç†ä¹‹å‰çš„æµ‹è¯•ç»“æœ
    test_log_dir = Path("sldc_logs_test_user")
    if test_log_dir.exists():
        shutil.rmtree(test_log_dir)
    
    print("ğŸ§ª å¼€å§‹æµ‹è¯•å¤šç§å­ç»“æœèšåˆ...")
    print(f"ğŸ“‹ æµ‹è¯•å‚æ•°: {test_args['lora_type']} on {test_args['dataset']}")
    print(f"ğŸŒ± æµ‹è¯•ç§å­: {test_args['seed_list']}")
    print("-" * 80)
    
    # å¯¼å…¥å¹¶è¿è¡Œè®­ç»ƒ
    try:
        from trainer import train
        results = train(test_args)
        
        # æ£€æŸ¥ç»“æœç»“æ„
        assert 'seeds' in results, "ç»“æœä¸­ç¼ºå°‘'seeds'é”®"
        assert 'aggregate' in results, "ç»“æœä¸­ç¼ºå°‘'aggregate'é”®"
        
        # æ£€æŸ¥ç§å­ç»“æœ
        seeds = results['seeds']
        assert len(seeds) == len(test_args['seed_list']), f"ç§å­æ•°é‡ä¸åŒ¹é…: {len(seeds)} vs {len(test_args['seed_list'])}"
        
        for seed_key in test_args['seed_list']:
            seed_key_str = f"seed_{seed_key}"
            assert seed_key_str in seeds, f"ç¼ºå°‘ç§å­{seed_key}çš„ç»“æœ"
        
        # æ£€æŸ¥èšåˆç»“æœ
        aggregate = results['aggregate']
        assert 'final_task' in aggregate, "èšåˆç»“æœä¸­ç¼ºå°‘'final_task'"
        assert 'average_across_tasks' in aggregate, "èšåˆç»“æœä¸­ç¼ºå°‘'average_across_tasks'"
        
        # æ£€æŸ¥èšåˆç»“æœæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        shared_log_dir = None
        for seed_result in seeds.values():
            if 'shared_log_dir' in seed_result:
                shared_log_dir = Path(seed_result['shared_log_dir'])
                break
        
        assert shared_log_dir is not None, "æ‰¾ä¸åˆ°å…±äº«æ—¥å¿—ç›®å½•"
        assert shared_log_dir.exists(), "å…±äº«æ—¥å¿—ç›®å½•ä¸å­˜åœ¨"
        
        aggregate_file = shared_log_dir / "aggregate_results.json"
        assert aggregate_file.exists(), "èšåˆç»“æœæ–‡ä»¶ä¸å­˜åœ¨"
        
        # æ£€æŸ¥èšåˆç»“æœæ–‡ä»¶å†…å®¹
        with open(aggregate_file, 'r', encoding='utf-8') as f:
            aggregate_data = json.load(f)
        
        assert 'final_task_stats' in aggregate_data, "èšåˆæ–‡ä»¶ä¸­ç¼ºå°‘'final_task_stats'"
        assert 'average_across_tasks_stats' in aggregate_data, "èšåˆæ–‡ä»¶ä¸­ç¼ºå°‘'average_across_tasks_stats'"
        assert 'seed_list' in aggregate_data, "èšåˆæ–‡ä»¶ä¸­ç¼ºå°‘'seed_list'"
        assert 'num_seeds' in aggregate_data, "èšåˆæ–‡ä»¶ä¸­ç¼ºå°‘'num_seeds'"
        
        # æ£€æŸ¥ç§å­åˆ—è¡¨
        seed_list = aggregate_data['seed_list']
        assert len(seed_list) == len(test_args['seed_list']), "èšåˆæ–‡ä»¶ä¸­çš„ç§å­æ•°é‡ä¸åŒ¹é…"
        
        # æ£€æŸ¥æ ‡å‡†å·®æ˜¯å¦ä¸º0ï¼ˆå¦‚æœæ˜¯0ï¼Œè¯´æ˜æ²¡æœ‰æ­£ç¡®èšåˆå¤šä¸ªç§å­ï¼‰
        for variant, stats in aggregate_data['final_task_stats'].items():
            std = stats['std']
            if std == 0.0:
                print(f"âš ï¸ è­¦å‘Š: å˜ä½“{variant}çš„æ ‡å‡†å·®ä¸º0ï¼Œå¯èƒ½æ²¡æœ‰æ­£ç¡®èšåˆå¤šä¸ªç§å­")
            else:
                print(f"âœ… å˜ä½“{variant}çš„æ ‡å‡†å·®ä¸º{std:.2f}ï¼Œèšåˆæ­£å¸¸")
        
        print("\nğŸ‰ æµ‹è¯•é€šè¿‡ï¼å¤šç§å­ç»“æœèšåˆå·¥ä½œæ­£å¸¸ã€‚")
        print(f"ğŸ“ èšåˆç»“æœä¿å­˜åœ¨: {aggregate_file}")
        print(f"ğŸŒ± åŒ…å«ç§å­: {seed_list}")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_aggregation()
    sys.exit(0 if success else 1)