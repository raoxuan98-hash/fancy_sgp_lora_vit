import torch
import torch.nn as nn
import timm
from lora import NullSpaceViT
import numpy as np

def test_gradient_projection():
    """æµ‹è¯•æ¢¯åº¦æŠ•å½±æœºåˆ¶"""
    print("=== æµ‹è¯•æ¢¯åº¦æŠ•å½±æœºåˆ¶ ===")
    
    # åˆ›å»ºæµ‹è¯•å‚æ•°
    args = {
        'vit_type': 'vit-b-p16',
        'lora_type': 'full',  # ä½¿ç”¨NullSpaceViT
        'use_projection': True
    }
    
    try:
        # åˆ›å»ºViTæ¨¡å‹
        vit = timm.create_model("vit_base_patch16_224", pretrained=False, num_classes=0)
        vit.head = nn.Identity()
        del vit.norm
        vit.norm = nn.LayerNorm(768, elementwise_affine=False)
        
        # ä½¿ç”¨NullSpaceViTåŒ…è£…
        nullspace_model = NullSpaceViT(vit, use_projection=True)
        print("âœ“ NullSpaceViTæ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        x = torch.randn(2, 3, 224, 224, requires_grad=True)
        output = nullspace_model(x)
        print(f"âœ“ å‰å‘ä¼ æ’­æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")
        
        # æµ‹è¯•åå‘ä¼ æ’­å’Œæ¢¯åº¦æŠ•å½±
        loss = output.sum()
        loss.backward()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ¢¯åº¦
        has_gradients = False
        for name, param in nullspace_model.named_parameters():
            if param.requires_grad and param.grad is not None:
                has_gradients = True
                print(f"âœ“ å‚æ•° {name} æœ‰æ¢¯åº¦ï¼Œå½¢çŠ¶: {param.grad.shape}")
                break
        
        if not has_gradients:
            print("âœ— æ²¡æœ‰æ‰¾åˆ°æ¢¯åº¦")
            return False
        
        # æµ‹è¯•æŠ•å½±çŸ©é˜µæ›´æ–°
        print("\n=== æµ‹è¯•æŠ•å½±çŸ©é˜µæ›´æ–° ===")
        
        # åˆ›å»ºæ¨¡æ‹Ÿçš„åæ–¹å·®çŸ©é˜µ
        module_names = nullspace_model.get_module_names()
        print(f"æ¨¡å—åç§°: {module_names[:3]}...")  # åªæ˜¾ç¤ºå‰3ä¸ª
        
        # åˆ›å»ºæ¨¡æ‹Ÿåæ–¹å·®çŸ©é˜µ
        mock_covariances = {}
        for name in module_names[:2]:  # åªæµ‹è¯•å‰2ä¸ªæ¨¡å—
            # è·å–å¯¹åº”å‚æ•°çš„å½¢çŠ¶
            for module_name, module in nullspace_model.lora_modules.items():
                if module_name == name and hasattr(module, 'weight'):
                    weight_shape = module.weight.shape
                    # åˆ›å»ºæ¨¡æ‹Ÿåæ–¹å·®çŸ©é˜µ
                    if len(weight_shape) == 2:  # çº¿æ€§å±‚
                        dim = weight_shape[1]  # è¾“å…¥ç»´åº¦
                        mock_cov = torch.randn(dim, dim)
                        mock_cov = mock_cov @ mock_cov.t()  # ç¡®ä¿æ­£å®š
                        mock_covariances[name] = mock_cov
                        print(f"âœ“ ä¸ºæ¨¡å— {name} åˆ›å»ºæ¨¡æ‹Ÿåæ–¹å·®çŸ©é˜µï¼Œå½¢çŠ¶: {mock_cov.shape}")
                    break
        
        # æ›´æ–°æŠ•å½±çŸ©é˜µ
        nullspace_model.update_projection_matrices(mock_covariances, soft=True, temp=1.0)
        print("âœ“ æŠ•å½±çŸ©é˜µæ›´æ–°æˆåŠŸ")
        
        # æ£€æŸ¥æŠ•å½±çŸ©é˜µæ˜¯å¦æ­£ç¡®å­˜å‚¨
        for name in mock_covariances.keys():
            if name in nullspace_model.projection_matrices:
                proj = nullspace_model.projection_matrices[name]
                print(f"âœ“ æ¨¡å— {name} çš„æŠ•å½±çŸ©é˜µå½¢çŠ¶: {proj.shape}")
                
                # éªŒè¯æŠ•å½±çŸ©é˜µçš„æ€§è´¨
                # 1. åº”è¯¥æ˜¯æ–¹é˜µ
                assert proj.shape[0] == proj.shape[1], f"æŠ•å½±çŸ©é˜µåº”è¯¥æ˜¯æ–¹é˜µï¼Œä½†å¾—åˆ°å½¢çŠ¶ {proj.shape}"
                
                # 2. åº”è¯¥æ˜¯å¯¹ç§°çš„ï¼ˆæ•°å€¼è¯¯å·®èŒƒå›´å†…ï¼‰
                diff = torch.max(torch.abs(proj - proj.t()))
                assert diff < 1e-5, f"æŠ•å½±çŸ©é˜µåº”è¯¥æ˜¯å¯¹ç§°çš„ï¼Œä½†æœ€å¤§ä¸å¯¹ç§°å·®å¼‚ä¸º {diff}"
                
                print(f"  - éªŒè¯é€šè¿‡: æ–¹é˜µä¸”å¯¹ç§°")
            else:
                print(f"âœ— æ¨¡å— {name} çš„æŠ•å½±çŸ©é˜µæœªæ‰¾åˆ°")
                return False
        
        # æµ‹è¯•æ¢¯åº¦æŠ•å½±åŠŸèƒ½
        print("\n=== æµ‹è¯•æ¢¯åº¦æŠ•å½±åŠŸèƒ½ ===")
        
        # æ¸…é›¶æ¢¯åº¦
        nullspace_model.zero_grad()
        
        # å†æ¬¡å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­
        x = torch.randn(2, 3, 224, 224, requires_grad=True)
        output = nullspace_model(x)
        loss = output.sum()
        loss.backward()
        
        # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦è¢«æŠ•å½±
        print("âœ“ æ¢¯åº¦æŠ•å½±æµ‹è¯•å®Œæˆ")
        
        # æµ‹è¯•å¼€å…³æŠ•å½±åŠŸèƒ½
        print("\n=== æµ‹è¯•æŠ•å½±å¼€å…³åŠŸèƒ½ ===")
        nullspace_model.disable_projection()
        print("âœ“ æŠ•å½±åŠŸèƒ½å·²ç¦ç”¨")
        
        nullspace_model.enable_projection()
        print("âœ“ æŠ•å½±åŠŸèƒ½å·²å¯ç”¨")
        
        return True
        
    except Exception as e:
        print(f"âœ— æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_gradient_projection()
    if success:
        print("\nğŸ‰ æ¢¯åº¦æŠ•å½±æœºåˆ¶æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("\nâŒ æ¢¯åº¦æŠ•å½±æœºåˆ¶æµ‹è¯•å¤±è´¥ï¼")