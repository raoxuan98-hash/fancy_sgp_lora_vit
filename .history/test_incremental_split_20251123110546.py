#!/usr/bin/env python3
"""
æµ‹è¯•cross-domainæ•°æ®é›†çš„å¢é‡æ‹†åˆ†åŠŸèƒ½
"""

import sys
import logging
from utils.balanced_cross_domain_data_manager import BalancedCrossDomainDataManagerCore

def test_incremental_split():
    """æµ‹è¯•å¢é‡æ‹†åˆ†åŠŸèƒ½"""
    print("=" * 80)
    print("æµ‹è¯•Cross-Domainæ•°æ®é›†çš„å¢é‡æ‹†åˆ†åŠŸèƒ½")
    print("=" * 80)
    
    # æµ‹è¯•æ•°æ®é›†
    test_datasets = ['cifar100_224', 'imagenet-r']
    
    print(f"\næµ‹è¯•æ•°æ®é›†: {test_datasets}")
    print(f"æ¯ä¸ªæ•°æ®é›†æ‹†åˆ†ä¸º3ä¸ªå¢é‡å­é›†")
    print("-" * 80)
    
    # åˆ›å»ºå¯ç”¨å¢é‡æ‹†åˆ†çš„æ•°æ®ç®¡ç†å™¨
    data_manager = BalancedCrossDomainDataManagerCore(
        dataset_names=test_datasets,
        balanced_datasets_root="balanced_datasets",
        shuffle=False,
        seed=1993,
        num_shots=0,
        log_level=logging.INFO,
        use_balanced_datasets=True,
        enable_incremental_split=True,
        num_incremental_splits=3,
        incremental_split_seed=42
    )
    
    print(f"\nâœ“ æ•°æ®ç®¡ç†å™¨åˆ›å»ºæˆåŠŸ")
    print(f"âœ“ æ€»ä»»åŠ¡æ•°: {data_manager.nb_tasks}")
    print(f"âœ“ æ€»ç±»åˆ«æ•°: {data_manager.num_classes}")
    
    # è·å–å¢é‡ç»Ÿè®¡ä¿¡æ¯
    incremental_stats = data_manager.get_incremental_statistics()
    
    print(f"\nå¢é‡æ‹†åˆ†ç»Ÿè®¡:")
    for original_name, stats in incremental_stats.items():
        print(f"\n  åŸå§‹æ•°æ®é›†: {original_name}")
        print(f"    æ‹†åˆ†æ•°: {stats['num_splits']}")
        print(f"    æ€»ç±»åˆ«: {stats['total_classes']}")
        print(f"    æ€»è®­ç»ƒæ ·æœ¬: {stats['total_train_samples']}")
        print(f"    æ€»æµ‹è¯•æ ·æœ¬: {stats['total_test_samples']}")
        
        for split in stats['splits']:
            print(f"      æ‹†åˆ† {split['split_index']} (ä»»åŠ¡ {split['task_id']}): "
                  f"{split['num_classes']} ç±»åˆ«, {split['train_samples']} è®­ç»ƒæ ·æœ¬")
    
    # æµ‹è¯•æ•°æ®è®¿é—®
    print(f"\næµ‹è¯•æ•°æ®è®¿é—®:")
    for task_id in range(data_manager.nb_tasks):
        dataset = data_manager.get_subset(task_id, source="train", mode="train")
        print(f"  ä»»åŠ¡ {task_id}: {len(dataset)} ä¸ªè®­ç»ƒæ ·æœ¬")
        
        # è·å–ç¬¬ä¸€ä¸ªæ ·æœ¬
        if len(dataset) > 0:
            image, label, class_name = dataset[0]
            print(f"    ç¬¬ä¸€ä¸ªæ ·æœ¬: æ ‡ç­¾={label}, ç±»åˆ«å={class_name}")
    
    # æµ‹è¯•åŸå§‹æ•°æ®é›†æ‹†åˆ†æ˜ å°„
    print(f"\næµ‹è¯•åŸå§‹æ•°æ®é›†æ‹†åˆ†æ˜ å°„:")
    for original_name in test_datasets:
        split_indices = data_manager.get_original_dataset_splits(original_name)
        print(f"  {original_name} -> ä»»åŠ¡ç´¢å¼•: {split_indices}")
    
    print(f"\n" + "=" * 80)
    print("âœ“ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    print("=" * 80)

def test_without_incremental_split():
    """æµ‹è¯•ä¸ä½¿ç”¨å¢é‡æ‹†åˆ†çš„æƒ…å†µï¼ˆå‘åå…¼å®¹æ€§ï¼‰"""
    print("\n" + "=" * 80)
    print("æµ‹è¯•ä¸ä½¿ç”¨å¢é‡æ‹†åˆ†ï¼ˆå‘åå…¼å®¹æ€§ï¼‰")
    print("=" * 80)
    
    test_datasets = ['cifar100_224']
    
    # åˆ›å»ºä¸å¯ç”¨å¢é‡æ‹†åˆ†çš„æ•°æ®ç®¡ç†å™¨
    data_manager = BalancedCrossDomainDataManagerCore(
        dataset_names=test_datasets,
        balanced_datasets_root="balanced_datasets",
        shuffle=False,
        seed=1993,
        num_shots=0,
        log_level=logging.INFO,
        use_balanced_datasets=True,
        enable_incremental_split=False  # ä¸å¯ç”¨å¢é‡æ‹†åˆ†
    )
    
    print(f"\nâœ“ æ•°æ®ç®¡ç†å™¨åˆ›å»ºæˆåŠŸï¼ˆæœªå¯ç”¨å¢é‡æ‹†åˆ†ï¼‰")
    print(f"âœ“ æ€»ä»»åŠ¡æ•°: {data_manager.nb_tasks}")
    print(f"âœ“ æ€»ç±»åˆ«æ•°: {data_manager.num_classes}")
    
    # éªŒè¯å¢é‡ç»Ÿè®¡åŠŸèƒ½
    try:
        incremental_stats = data_manager.get_incremental_statistics()
        if not incremental_stats:
            print("âœ“ å¢é‡ç»Ÿè®¡åŠŸèƒ½æ­£ç¡®è¿”å›ç©ºç»“æœï¼ˆæœªå¯ç”¨å¢é‡æ‹†åˆ†ï¼‰")
        else:
            print("âœ— å¢é‡ç»Ÿè®¡åŠŸèƒ½è¿”å›äº†éç©ºç»“æœï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼‰")
    except Exception as e:
        print(f"âœ— å¢é‡ç»Ÿè®¡åŠŸèƒ½å‡ºé”™: {e}")
    
    print(f"\n" + "=" * 80)
    print("âœ“ å‘åå…¼å®¹æ€§æµ‹è¯•é€šè¿‡ï¼")
    print("=" * 80)

if __name__ == "__main__":
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logging.basicConfig(level=logging.INFO)
    
    try:
        # æµ‹è¯•å¢é‡æ‹†åˆ†åŠŸèƒ½
        test_incremental_split()
        
        # æµ‹è¯•å‘åå…¼å®¹æ€§
        test_without_incremental_split()
        
        print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)