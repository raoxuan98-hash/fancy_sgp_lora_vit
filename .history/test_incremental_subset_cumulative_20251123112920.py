#!/usr/bin/env python3
"""
æµ‹è¯• get_incremental_subset æ–¹æ³•çš„ cumulative å‚æ•°åŠŸèƒ½
"""

import os
import sys
import logging
import numpy as np
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from utils.balanced_cross_domain_data_manager import create_balanced_data_manager

def test_cumulative_functionality():
    """æµ‹è¯• cumulative å‚æ•°åŠŸèƒ½"""
    print("=== æµ‹è¯• get_incremental_subset çš„ cumulative å‚æ•°åŠŸèƒ½ ===\n")
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    
    # åˆ›å»ºæµ‹è¯•ç”¨çš„æ•°æ®ç®¡ç†å™¨ï¼ˆå¯ç”¨å¢é‡æ‹†åˆ†ï¼‰
    datasets = ['cifar100_224', 'cub200_224']
    
    try:
        manager = create_balanced_data_manager(
            dataset_names=datasets,
            balanced_datasets_root="balanced_datasets",
            use_balanced_datasets=True,
            enable_incremental_split=True,
            num_incremental_splits=3,
            incremental_split_seed=42
        )
        
        print(f"âœ… æˆåŠŸåˆ›å»ºæ•°æ®ç®¡ç†å™¨")
        print(f"   æ€»ä»»åŠ¡æ•°: {manager.nb_tasks}")
        print(f"   æ€»ç±»åˆ«æ•°: {manager.num_classes}")
        print(f"   æ•°æ®é›†åç§°: {manager.dataset_names}")
        
        # æ˜¾ç¤ºå¢é‡æ‹†åˆ†ç»Ÿè®¡ä¿¡æ¯
        incremental_stats = manager.get_incremental_statistics()
        print(f"\nğŸ“Š å¢é‡æ‹†åˆ†ç»Ÿè®¡ä¿¡æ¯:")
        for original_name, stat in incremental_stats.items():
            print(f"   åŸå§‹æ•°æ®é›†: {original_name}")
            print(f"     æ‹†åˆ†æ•°: {stat['num_splits']}")
            print(f"     æ€»ç±»åˆ«: {stat['total_classes']}")
            print(f"     æ‹†åˆ†ä¿¡æ¯:")
            for split in stat['splits']:
                print(f"       æ‹†åˆ† {split['split_index']} (ä»»åŠ¡ {split['task_id']}): {split['num_classes']} ç±»åˆ«")
        
        print(f"\nğŸ§ª æµ‹è¯• cumulative=False (éç´¯ç§¯æ¨¡å¼)")
        for task_id in range(min(3, manager.nb_tasks)):  # æµ‹è¯•å‰3ä¸ªä»»åŠ¡
            try:
                # æµ‹è¯•éç´¯ç§¯æ¨¡å¼
                subset_non_cumulative = manager.get_incremental_subset(
                    task=task_id, 
                    source="test", 
                    cumulative=False
                )
                print(f"   ä»»åŠ¡ {task_id} (éç´¯ç§¯): æ•°æ®é›†é•¿åº¦ = {len(subset_non_cumulative)}")
                
                # è·å–æ•°æ®é›†ä¿¡æ¯
                dataset_info = manager.datasets[task_id]
                print(f"     æ•°æ®é›†åç§°: {dataset_info['name']}")
                print(f"     ç±»åˆ«æ•°: {dataset_info['num_classes']}")
                print(f"     æ ‡ç­¾èŒƒå›´: {dataset_info['test_targets'].min()} - {dataset_info['test_targets'].max()}")
                
            except Exception as e:
                print(f"   âŒ ä»»åŠ¡ {task_id} æµ‹è¯•å¤±è´¥: {e}")
                return False
        
        print(f"\nğŸ§ª æµ‹è¯• cumulative=True (ç´¯ç§¯æ¨¡å¼)")
        for task_id in range(min(3, manager.nb_tasks)):  # æµ‹è¯•å‰3ä¸ªä»»åŠ¡
            try:
                # æµ‹è¯•ç´¯ç§¯æ¨¡å¼
                subset_cumulative = manager.get_incremental_subset(
                    task=task_id, 
                    source="test", 
                    cumulative=True
                )
                print(f"   ä»»åŠ¡ {task_id} (ç´¯ç§¯): æ•°æ®é›†é•¿åº¦ = {len(subset_cumulative)}")
                
                # éªŒè¯ç´¯ç§¯æ•°æ®åº”è¯¥åŒ…å«æ‰€æœ‰ä¹‹å‰ä»»åŠ¡çš„æ•°æ®
                total_expected_samples = 0
                for i in range(task_id + 1):
                    total_expected_samples += len(manager.datasets[i]['test_data'])
                
                if len(subset_cumulative) >= total_expected_samples:
                    print(f"     âœ… ç´¯ç§¯æ¨¡å¼éªŒè¯é€šè¿‡ (æœŸæœ›: {total_expected_samples}, å®é™…: {len(subset_cumulative)})")
                else:
                    print(f"     âŒ ç´¯ç§¯æ¨¡å¼éªŒè¯å¤±è´¥ (æœŸæœ›: {total_expected_samples}, å®é™…: {len(subset_cumulative)})")
                    return False
                
            except Exception as e:
                print(f"   âŒ ä»»åŠ¡ {task_id} ç´¯ç§¯æ¨¡å¼æµ‹è¯•å¤±è´¥: {e}")
                return False
        
        print(f"\nğŸ§ª æµ‹è¯•å‘åå…¼å®¹æ€§ (ä¸æŒ‡å®š cumulative å‚æ•°)")
        for task_id in range(min(2, manager.nb_tasks)):
            try:
                # é»˜è®¤åº”è¯¥ä¸º cumulative=False
                subset_default = manager.get_incremental_subset(
                    task=task_id, 
                    source="test"
                )
                subset_explicit_false = manager.get_incremental_subset(
                    task=task_id, 
                    source="test", 
                    cumulative=False
                )
                
                if len(subset_default) == len(subset_explicit_false):
                    print(f"   âœ… ä»»åŠ¡ {task_id}: å‘åå…¼å®¹æ€§æµ‹è¯•é€šè¿‡")
                else:
                    print(f"   âŒ ä»»åŠ¡ {task_id}: å‘åå…¼å®¹æ€§æµ‹è¯•å¤±è´¥")
                    return False
                    
            except Exception as e:
                print(f"   âŒ ä»»åŠ¡ {task_id} å‘åå…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
                return False
        
        print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼get_incremental_subset çš„ cumulative å‚æ•°åŠŸèƒ½æ­£å¸¸")
        return True
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºæ•°æ®ç®¡ç†å™¨å¤±è´¥: {e}")
        return False

def test_compatibility_with_subspace_lora():
    """æµ‹è¯•ä¸ subspace_lora.py çš„å…¼å®¹æ€§"""
    print(f"\n=== æµ‹è¯•ä¸ subspace_lora.py çš„å…¼å®¹æ€§ ===\n")
    
    try:
        # æ¨¡æ‹Ÿ subspace_lora.py ä¸­çš„ä½¿ç”¨æ–¹å¼
        datasets = ['cifar100_224']
        
        manager = create_balanced_data_manager(
            dataset_names=datasets,
            balanced_datasets_root="balanced_datasets",
            use_balanced_datasets=True,
            enable_incremental_split=True,
            num_incremental_splits=2,
            incremental_split_seed=42
        )
        
        task_id = 0
        
        # æ¨¡æ‹Ÿ subspace_lora.py ä¸­çš„è°ƒç”¨æ–¹å¼
        print("ğŸ§ª æ¨¡æ‹Ÿ subspace_lora.py ä¸­çš„ä½¿ç”¨æ¨¡å¼:")
        
        # è®­ç»ƒé›† (cumulative=False)
        train_set = manager.get_incremental_subset(
            task=task_id, source="train", cumulative=False, mode="train")
        print(f"   è®­ç»ƒé›† (cumulative=False): {len(train_set)} æ ·æœ¬")
        
        # æµ‹è¯•é›† (cumulative=True)
        test_set = manager.get_incremental_subset(
            task=task_id, source="test", cumulative=True, mode="test")
        print(f"   æµ‹è¯•é›† (cumulative=True): {len(test_set)} æ ·æœ¬")
        
        # è®­ç»ƒé›†æµ‹è¯•æ¨¡å¼ (cumulative=False)
        train_set_test_mode = manager.get_incremental_subset(
            task=task_id, source="train", cumulative=False, mode="test")
        print(f"   è®­ç»ƒé›†æµ‹è¯•æ¨¡å¼ (cumulative=False): {len(train_set_test_mode)} æ ·æœ¬")
        
        print(f"âœ… ä¸ subspace_lora.py çš„å…¼å®¹æ€§æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ ä¸ subspace_lora.py çš„å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯• get_incremental_subset çš„ cumulative å‚æ•°åŠŸèƒ½\n")
    
    # æ£€æŸ¥å¹³è¡¡æ•°æ®é›†æ˜¯å¦å­˜åœ¨
    balanced_datasets_root = Path("balanced_datasets")
    if not balanced_datasets_root.exists():
        print("âš ï¸  è­¦å‘Š: balanced_datasets ç›®å½•ä¸å­˜åœ¨ï¼ŒæŸäº›æµ‹è¯•å¯èƒ½å¤±è´¥")
    
    # è¿è¡Œæµ‹è¯•
    test1_passed = test_cumulative_functionality()
    test2_passed = test_compatibility_with_subspace_lora()
    
    if test1_passed and test2_passed:
        print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼åŠŸèƒ½å®æ–½æˆåŠŸ")
        return True
    else:
        print(f"\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)