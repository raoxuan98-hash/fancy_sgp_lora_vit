#!/usr/bin/env python3
"""
Standalone test script to verify the new log naming system works correctly
for different LoRA types and knowledge distillation configurations.
This script only tests the build_log_dirs function without importing the entire project.
"""

import sys
import os
import tempfile
import json
import logging
import io

# Import only the necessary functions from trainer.py
def _fmt(x, *, digits=4):
    """
    å‹ç¼©æ•°å€¼åˆ°çŸ­å­—ç¬¦ä¸²ï¼š0.5 -> 0p5, 1e-3 -> 1e-03, 0.200 -> 0p2
    ä½œç”¨ï¼šå‡å°‘è·¯å¾„é•¿åº¦ã€é¿å…å°æ•°ç‚¹è¿‡å¤šã€‚
    """
    if isinstance(x, bool):
        return "1" if x else "0"
    if isinstance(x, int):
        return str(x)
    try:
        s = f"{float(x):.{digits}g}"
        s = s.replace('.', 'p')
        return s
    except Exception:
        s = str(x)
        s = s.replace('.', 'p')
        return s

def sanitize_filename(s: str) -> str:
    """ç§»é™¤æˆ–æ›¿æ¢æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦"""
    import re
    # Windows éæ³•å­—ç¬¦: \ / : * ? " < > |
    s = re.sub(r'[\\/:*?"<>|]', '_', str(s))
    # å¯é€‰ï¼šå‹ç¼©è¿ç»­ä¸‹åˆ’çº¿
    s = re.sub(r'_+', '_', s)
    return s.strip('_')

def short(s: str, maxlen=40):
    """æˆªæ–­è¿‡é•¿å­—ç¬¦ä¸²ï¼Œä¸åŠ  hashï¼Œä»…ä¿ç•™å¯è¯»æ€§"""
    s = sanitize_filename(str(s))
    if len(s) <= maxlen:
        return s
    return s[:maxlen].rstrip('_')  # é¿å…æˆªæ–­åœ¨ä¸‹åˆ’çº¿å¤„

def _filter_args_by_lora_type(args: dict) -> dict:
    """
    è¿‡æ»¤å‚æ•°å­—å…¸ï¼Œåªä¿ç•™ä¸å½“å‰LoRAç±»å‹ç›¸å…³çš„å‚æ•°
    è¿™æ ·å¯ä»¥é¿å…åœ¨params.jsonä¸­ä¿å­˜ä¸ç›¸å…³çš„å‚æ•°ï¼Œå¯¼è‡´æ—¥å¿—å‘½åæ··ä¹±
    """
    lora_type = args.get('lora_type', 'basic_lora')
    filtered_args = args.copy()
    
    # å®šä¹‰æ¯ç§LoRAç±»å‹ç›¸å…³çš„å‚æ•°
    sgp_lora_params = {'weight_temp', 'weight_kind', 'weight_p'}
    nsp_lora_params = {'nsp_eps', 'nsp_weight'}
    
    # ç§»é™¤ä¸å½“å‰LoRAç±»å‹ä¸ç›¸å…³çš„å‚æ•°
    if lora_type == 'sgp_lora':
        # ä¿ç•™SGPå‚æ•°ï¼Œç§»é™¤NSPå‚æ•°
        for param in nsp_lora_params:
            filtered_args.pop(param, None)
    elif lora_type == 'nsp_lora':
        # ä¿ç•™NSPå‚æ•°ï¼Œç§»é™¤SGPå‚æ•°
        for param in sgp_lora_params:
            filtered_args.pop(param, None)
    elif lora_type == 'basic_lora':
        # ç§»é™¤æ‰€æœ‰LoRAç‰¹å®šå‚æ•°
        for param in sgp_lora_params.union(nsp_lora_params):
            filtered_args.pop(param, None)
    elif lora_type == 'full':
        # ç§»é™¤æ‰€æœ‰LoRAç‰¹å®šå‚æ•°
        for param in sgp_lora_params.union(nsp_lora_params):
            filtered_args.pop(param, None)
    
    return filtered_args

def _get_lora_specific_params(lora_type: str, args: dict) -> list:
    """è·å–ç‰¹å®š LoRA ç±»å‹çš„å‚æ•°ï¼Œé¿å…äº¤å‰æ±¡æŸ“"""
    params = []
    
    if lora_type == 'sgp_lora':
        # SGP LoRA ç‰¹æœ‰å‚æ•°
        if 'weight_temp' in args:
            params.append(f"t-{short(args['weight_temp'])}")
        if 'weight_kind' in args:
            params.append(f"k-{short(args['weight_kind'])}")
        if 'weight_p' in args:
            params.append(f"p-{short(args['weight_p'])}")
            
    elif lora_type == 'nsp_lora':
        # NSP LoRA ç‰¹æœ‰å‚æ•°
        if 'nsp_eps' in args:
            params.append(f"eps-{short(args['nsp_eps'])}")
        if 'nsp_weight' in args:
            params.append(f"w-{short(args['nsp_weight'])}")
            
    elif lora_type == 'basic_lora':
        # Basic LoRA é€šå¸¸æ²¡æœ‰é¢å¤–å‚æ•°ï¼Œä½†å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
        pass
        
    elif lora_type == 'full':
        # Full fine-tuning å¯èƒ½æœ‰çš„å‚æ•°
        pass
        
    return params

def _get_kd_params(args: dict) -> list:
    """è·å–çŸ¥è¯†è’¸é¦ç›¸å…³å‚æ•°ï¼Œç»Ÿä¸€å‘½åè§„åˆ™"""
    kd_params = []
    
    if args.get('gamma_kd', 0.0) > 0.0:
        kd_params.append(f"kd-{short(args['gamma_kd'])}")
        if 'kd_type' in args:
            kd_params.append(f"type-{short(args['kd_type'])}")
        if 'distillation_transform' in args:
            kd_params.append(f"dt-{short(args['distillation_transform'])}")
        if args.get('use_aux_for_kd', False):
            kd_params.append("aux")
        # æ·»åŠ update_teacher_each_taskå‚æ•°ï¼Œç®€å†™ä¸ºutt
        if 'update_teacher_each_task' in args:
            kd_params.append(f"utt-{short(args['update_teacher_each_task'])}")
            
    return kd_params

def _validate_parameters(args: dict) -> None:
    """éªŒè¯å‚æ•°ç»„åˆçš„åˆç†æ€§"""
    lora_type = args.get('lora_type', 'basic_lora')
    
    # æ£€æŸ¥ LoRA ç‰¹å®šå‚æ•°æ˜¯å¦è¢«è¯¯ç”¨
    if lora_type != 'sgp_lora':
        sgp_params = ['weight_temp', 'weight_kind', 'weight_p']
        for param in sgp_params:
            if param in args and args[param] is not None:
                logging.warning(f"âš ï¸ Parameter '{param}' is being used with lora_type='{lora_type}', but it's specific to sgp_lora")
    
    if lora_type != 'nsp_lora':
        nsp_params = ['nsp_eps', 'nsp_weight']
        for param in nsp_params:
            if param in args and args[param] is not None:
                logging.warning(f"âš ï¸ Parameter '{param}' is being used with lora_type='{lora_type}', but it's specific to nsp_lora")

def build_log_dirs(args: dict, root_dir="."):
    """æ ¹æ® args æ„å»ºå¤šçº§æ—¥å¿—ç›®å½•ï¼Œç¡®ä¿ä¸åŒ LoRA ç±»å‹çš„å‚æ•°æ­£ç¡®åˆ†ç¦»"""

    # å‚æ•°éªŒè¯
    _validate_parameters(args)

    # é¡¶å±‚ï¼šæ¨¡å‹å’Œç”¨æˆ·ä¿¡æ¯
    base_dir = os.path.join(
        root_dir,
        f"{short(args['model_name'])}_logs_{short(args['user'])}",
        f"{short(args['dataset'])}_{short(args['vit_type'])}"
    )

    # äºŒçº§ï¼šä»»åŠ¡è®¾ç½®
    task_dir = os.path.join(
        base_dir,
        f"init-{short(args['init_cls'])}_inc-{short(args['increment'])}",
        f"lrank-{short(args.get('lora_rank', 'NA'))}_ltype-{short(args.get('lora_type', 'NA'))}"
    )

    # ä¸‰çº§ï¼šLoRA ç‰¹å®šå‚æ•°ï¼ˆåªåŒ…å«ç›¸å…³çš„ï¼‰
    lora_params = _get_lora_specific_params(args.get('lora_type', 'basic_lora'), args)
    
    # å››çº§ï¼šçŸ¥è¯†è’¸é¦å‚æ•°ï¼ˆå¦‚æœæœ‰ï¼‰
    kd_params = _get_kd_params(args)
    
    # åˆå¹¶ LoRA å’Œ KD å‚æ•°
    method_params = lora_params + kd_params
    
    # æ„å»ºæ–¹æ³•å‚æ•°ç›®å½•
    if method_params:
        method_subdir = "_".join(method_params)
        method_dir = os.path.join(task_dir, short(method_subdir, maxlen=80))
    else:
        method_dir = task_dir

    # äº”çº§ï¼šä¼˜åŒ–å™¨å’Œè®­ç»ƒå‚æ•°
    opt_params = [
        f"opt-{args['optimizer']}",
        f"lr-{short(args['lrate'])}",
        f"b-{args['batch_size']}",
        f"i-{args['iterations']}",
        f"s-{args['seed']}"
    ]
    opt_str = "_".join(opt_params)
    opt_dir = os.path.join(method_dir, short(opt_str, maxlen=80))

    # === é€çº§åˆ›å»ºç›®å½• ===
    abs_log_dir = os.path.abspath(opt_dir)
    current = os.path.abspath(os.sep)
    for part in abs_log_dir.split(os.sep)[1:]:
        current = os.path.join(current, part)
        if not os.path.exists(current):
            os.makedirs(current)

    # ä¿å­˜è¿‡æ»¤åçš„å‚æ•°åˆ° JSONï¼Œé¿å…å‚æ•°äº¤å‰æ±¡æŸ“
    filtered_args = _filter_args_by_lora_type(args)
    params_json = os.path.join(abs_log_dir, "params.json")
    if not os.path.exists(params_json):
        with open(params_json, "w", encoding="utf-8") as f:
            json.dump(filtered_args, f, ensure_ascii=False, indent=2)

    # è®°å½•ç”Ÿæˆçš„ç›®å½•ç»“æ„ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    logging.info(f"ğŸ“ Log directory created: {abs_log_dir}")
    logging.info(f"   LoRA params: {lora_params}")
    logging.info(f"   KD params: {kd_params}")
    
    # è®°å½•è¿‡æ»¤ä¿¡æ¯
    original_params = set(args.keys())
    filtered_params = set(filtered_args.keys())
    removed_params = original_params - filtered_params
    if removed_params:
        logging.info(f"   è¿‡æ»¤æ‰çš„å‚æ•°: {sorted(removed_params)}")

    return os.path.dirname(abs_log_dir), str(abs_log_dir)

# Test functions
def test_sgp_lora_naming():
    """Test SGP LoRA naming without KD"""
    print("ğŸ§ª Testing SGP LoRA naming...")
    
    args = {
        'model_name': 'sldc',
        'user': 'test_user',
        'dataset': 'cifar100_224',
        'vit_type': 'vit-b-p16-mocov3',
        'init_cls': 10,
        'increment': 10,
        'lora_rank': 4,
        'lora_type': 'sgp_lora',
        'weight_temp': 2.0,
        'weight_kind': 'log1p',
        'weight_p': 1.0,
        'gamma_kd': 0.0,  # No KD
        'optimizer': 'adamw',
        'lrate': 1e-4,
        'batch_size': 16,
        'iterations': 2000,
        'seed': 1993
    }
    
    with tempfile.TemporaryDirectory() as temp_dir:
        _, log_path = build_log_dirs(args, root_dir=temp_dir)
        print(f"   Generated path: {log_path}")
        
        # Verify SGP parameters are included
        assert "t-2p0" in log_path, f"weight_temp not found in {log_path}"
        assert "k-log1p" in log_path, f"weight_kind not found in {log_path}"
        assert "p-1" in log_path, f"weight_p not found in {log_path}"
        
        # Verify NSP parameters are NOT included
        assert "eps-" not in log_path, f"nsp_eps found in {log_path} but shouldn't be"
        assert "w-" not in log_path or "w-" not in log_path.split("ltype-sgp_lora")[1].split("/")[0], f"nsp_weight found in {log_path} but shouldn't be"
        
        # Verify KD parameters are NOT included
        assert "kd-" not in log_path, f"KD parameters found but gamma_kd=0"
        
        # Verify params.json doesn't contain NSP parameters
        params_file = os.path.join(log_path, "params.json")
        with open(params_file, 'r') as f:
            params = json.load(f)
        assert 'nsp_eps' not in params, f"nsp_eps found in params.json but shouldn't be"
        assert 'nsp_weight' not in params, f"nsp_weight found in params.json but shouldn't be"
        
    print("   âœ… SGP LoRA naming test passed")

def test_nsp_lora_naming():
    """Test NSP LoRA naming without KD"""
    print("ğŸ§ª Testing NSP LoRA naming...")
    
    args = {
        'model_name': 'sldc',
        'user': 'test_user',
        'dataset': 'cifar100_224',
        'vit_type': 'vit-b-p16-mocov3',
        'init_cls': 10,
        'increment': 10,
        'lora_rank': 4,
        'lora_type': 'nsp_lora',
        'nsp_eps': 0.05,
        'nsp_weight': 0.02,
        'gamma_kd': 0.0,  # No KD
        'optimizer': 'adamw',
        'lrate': 1e-4,
        'batch_size': 16,
        'iterations': 2000,
        'seed': 1993
    }
    
    with tempfile.TemporaryDirectory() as temp_dir:
        _, log_path = build_log_dirs(args, root_dir=temp_dir)
        print(f"   Generated path: {log_path}")
        
        # Verify NSP parameters are included
        assert "eps-0p05" in log_path, f"nsp_eps not found in {log_path}"
        assert "w-0p02" in log_path, f"nsp_weight not found in {log_path}"
        
        # Verify SGP parameters are NOT included
        assert "t-" not in log_path or "t-" not in log_path.split("ltype-nsp_lora")[1].split("/")[0], f"weight_temp found in {log_path} but shouldn't be"
        assert "k-" not in log_path or "k-" not in log_path.split("ltype-nsp_lora")[1].split("/")[0], f"weight_kind found in {log_path} but shouldn't be"
        
        # Verify KD parameters are NOT included
        assert "kd-" not in log_path, f"KD parameters found but gamma_kd=0"
        
        # Verify params.json doesn't contain SGP parameters
        params_file = os.path.join(log_path, "params.json")
        with open(params_file, 'r') as f:
            params = json.load(f)
        assert 'weight_temp' not in params, f"weight_temp found in params.json but shouldn't be"
        assert 'weight_kind' not in params, f"weight_kind found in params.json but shouldn't be"
        assert 'weight_p' not in params, f"weight_p found in params.json but shouldn't be"
        
    print("   âœ… NSP LoRA naming test passed")

def test_parameter_filtering():
    """Test that parameters are correctly filtered in params.json"""
    print("ğŸ§ª Testing parameter filtering in params.json...")
    
    # Test NSP LoRA - should not have SGP parameters in params.json
    args = {
        'model_name': 'sldc',
        'user': 'test_user',
        'dataset': 'cifar100_224',
        'vit_type': 'vit-b-p16-mocov3',
        'init_cls': 10,
        'increment': 10,
        'lora_rank': 4,
        'lora_type': 'nsp_lora',
        'nsp_eps': 0.05,
        'nsp_weight': 0.02,
        'weight_temp': 2.0,  # Should be filtered out
        'weight_kind': 'log1p',  # Should be filtered out
        'weight_p': 1.0,  # Should be filtered out
        'gamma_kd': 0.0,
        'optimizer': 'adamw',
        'lrate': 1e-4,
        'batch_size': 16,
        'iterations': 2000,
        'seed': 1993
    }
    
    with tempfile.TemporaryDirectory() as temp_dir:
        _, log_path = build_log_dirs(args, root_dir=temp_dir)
        
        # Check params.json content
        params_file = os.path.join(log_path, "params.json")
        with open(params_file, 'r') as f:
            params = json.load(f)
        
        # Should have NSP parameters
        assert 'nsp_eps' in params, f"nsp_eps not found in params.json"
        assert 'nsp_weight' in params, f"nsp_weight not found in params.json"
        
        # Should NOT have SGP parameters
        assert 'weight_temp' not in params, f"weight_temp found in params.json but should be filtered"
        assert 'weight_kind' not in params, f"weight_kind found in params.json but should be filtered"
        assert 'weight_p' not in params, f"weight_p found in params.json but should be filtered"
    
    print("   âœ… Parameter filtering test passed")

def main():
    """Run all tests"""
    print("ğŸš€ Testing new log naming system...")
    print("=" * 60)
    
    # Set up logging to capture warnings
    logging.basicConfig(level=logging.WARNING, format='%(message)s')
    
    try:
        test_sgp_lora_naming()
        test_nsp_lora_naming()
        test_parameter_filtering()
        
        print("=" * 60)
        print("ğŸ‰ All tests passed! The new log naming system works correctly.")
        print("\nğŸ“‹ Summary of improvements:")
        print("   âœ… LoRA-specific parameters are properly isolated")
        print("   âœ… No cross-contamination between different LoRA types")
        print("   âœ… Knowledge distillation parameters are clearly separated")
        print("   âœ… Directory structure is clean and descriptive")
        print("   âœ… Parameters are correctly filtered in params.json")
        
    except AssertionError as e:
        print(f"âŒ Test failed: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()