#!/usr/bin/env python3
"""
å¯è§†åŒ–è„šæœ¬ï¼šå±•ç¤ºå‡†ç¡®åº¦éšä»»åŠ¡æ•°é‡å¢åŠ çš„ä¸‹é™è¶‹åŠ¿
ä½¿ç”¨aggregate_results.jsonä¸­çš„per_task_accuracy_trendsæ•°æ®
"""

import json
import matplotlib.pyplot as plt
import numpy as np
import os
from pathlib import Path

def visualize_accuracy_trends(aggregate_file):
    """
    å¯è§†åŒ–å‡†ç¡®åº¦éšä»»åŠ¡æ•°é‡å¢åŠ çš„ä¸‹é™è¶‹åŠ¿
    
    Args:
        aggregate_file: aggregate_results.jsonæ–‡ä»¶è·¯å¾„
    """
    try:
        with open(aggregate_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«per_task_accuracy_trendså­—æ®µ
    if "per_task_accuracy_trends" not in data:
        print("âŒ æ–‡ä»¶ä¸­ä¸åŒ…å«per_task_accuracy_trendså­—æ®µ")
        print("ğŸ’¡ è¯·ç¡®ä¿ä½¿ç”¨ä¿®æ”¹åçš„ä»£ç è¿è¡Œmain.pyç”Ÿæˆæ–°çš„aggregate_results.json")
        return
    
    trends = data["per_task_accuracy_trends"]
    variants = list(trends.keys())
    
    if not variants:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å˜ä½“çš„å‡†ç¡®åº¦è¶‹åŠ¿æ•°æ®")
        return
    
    # åˆ›å»ºå›¾å½¢
    plt.figure(figsize=(12, 8))
    
    # ä¸ºæ¯ä¸ªå˜ä½“ç»˜åˆ¶å‡†ç¡®åº¦è¶‹åŠ¿çº¿
    for variant in variants:
        trend_data = trends[variant]
        means = trend_data.get("means", [])
        stds = trend_data.get("stds", [])
        
        if not means:
            continue
        
        # ä»»åŠ¡ç¼–å·ï¼ˆä»1å¼€å§‹ï¼‰
        task_ids = list(range(1, len(means) + 1))
        
        # ç»˜åˆ¶ä¸»è¶‹åŠ¿çº¿
        plt.plot(task_ids, means, marker='o', linewidth=2, label=variant)
        
        # ç»˜åˆ¶æ ‡å‡†å·®èŒƒå›´ï¼ˆå¦‚æœæœ‰ï¼‰
        if stds and any(s > 0 for s in stds):
            means_array = np.array(means)
            stds_array = np.array(stds)
            plt.fill_between(task_ids, 
                           means_array - stds_array, 
                           means_array + stds_array, 
                           alpha=0.2)
    
    # è®¾ç½®å›¾å½¢å±æ€§
    plt.xlabel('ä»»åŠ¡ç¼–å·', fontsize=14)
    plt.ylabel('å‡†ç¡®åº¦ (%)', fontsize=14)
    plt.title('å‡†ç¡®åº¦éšä»»åŠ¡æ•°é‡å¢åŠ çš„å˜åŒ–è¶‹åŠ¿', fontsize=16)
    plt.grid(True, alpha=0.3)
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    
    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout()
    
    # ä¿å­˜å›¾å½¢
    output_file = Path(aggregate_file).parent / "accuracy_trends.png"
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"ğŸ“Š å‡†ç¡®åº¦è¶‹åŠ¿å›¾å·²ä¿å­˜åˆ°: {output_file}")
    
    # æ˜¾ç¤ºå›¾å½¢ï¼ˆå¦‚æœåœ¨äº¤äº’ç¯å¢ƒä¸­ï¼‰
    try:
        plt.show()
    except:
        print("ğŸ’¡ æ— æ³•æ˜¾ç¤ºå›¾å½¢ï¼Œä½†å·²ä¿å­˜åˆ°æ–‡ä»¶")
    
    # æ‰“å°æ•°æ®æ‘˜è¦
    print("\nğŸ“ˆ å‡†ç¡®åº¦è¶‹åŠ¿æ•°æ®æ‘˜è¦:")
    for variant in variants:
        trend_data = trends[variant]
        means = trend_data.get("means", [])
        if means:
            initial_acc = means[0]
            final_acc = means[-1]
            drop = initial_acc - final_acc
            drop_rate = drop / initial_acc * 100
            
            print(f"  {variant}:")
            print(f"    åˆå§‹å‡†ç¡®åº¦: {initial_acc:.2f}%")
            print(f"    æœ€ç»ˆå‡†ç¡®åº¦: {final_acc:.2f}%")
            print(f"    ä¸‹é™å¹…åº¦: {drop:.2f}% ({drop_rate:.1f}%)")

def create_sample_visualization():
    """ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®åˆ›å»ºç¤ºä¾‹å¯è§†åŒ–"""
    # æ¨¡æ‹Ÿæ•°æ®
    sample_data = {
        "per_task_accuracy_trends": {
            "SeqFT + LDA": {
                "means": [85.5, 82.3, 78.9, 75.2, 72.1, 68.08],
                "stds": [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
                "num_tasks": 6
            },
            "SeqFT + QDA": {
                "means": [88.2, 85.1, 81.7, 78.3, 75.6, 73.8],
                "stds": [0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
                "num_tasks": 6
            },
            "SeqFT + attention_transform + QDA": {
                "means": [90.1, 87.5, 84.2, 81.0, 78.5, 76.2],
                "stds": [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],
                "num_tasks": 6
            }
        }
    }
    
    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
    temp_file = Path("temp_sample_data.json")
    with open(temp_file, 'w', encoding='utf-8') as f:
        json.dump(sample_data, f, indent=2)
    
    print("ğŸ“Š ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®åˆ›å»ºç¤ºä¾‹å¯è§†åŒ–...")
    visualize_accuracy_trends(str(temp_file))
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    temp_file.unlink()
    print("âœ… ç¤ºä¾‹å¯è§†åŒ–å®Œæˆ")

if __name__ == "__main__":
    print("ğŸ¨ å‡†ç¡®åº¦è¶‹åŠ¿å¯è§†åŒ–å·¥å…·")
    print("=" * 50)
    
    # æŸ¥æ‰¾æœ€æ–°çš„aggregate_results.jsonæ–‡ä»¶
    log_dirs = [
        "sldc_logs_sgp_lora_vit_main",
        "sldc_logs_sgp_lora",
        "sldc_logs_sgp_lora_test",
        "test_results"
    ]
    
    found_files = []
    for log_dir in log_dirs:
        if os.path.exists(log_dir):
            for root, dirs, files in os.walk(log_dir):
                if "aggregate_results.json" in files:
                    found_files.append(os.path.join(root, "aggregate_results.json"))
    
    if found_files:
        # ä½¿ç”¨æœ€æ–°çš„æ–‡ä»¶
        latest_file = max(found_files, key=os.path.getmtime)
        print(f"ğŸ“„ ä½¿ç”¨æ–‡ä»¶: {latest_file}")
        visualize_accuracy_trends(latest_file)
    else:
        print("ğŸ“„ æœªæ‰¾åˆ°aggregate_results.jsonæ–‡ä»¶ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®åˆ›å»ºç¤ºä¾‹...")
        create_sample_visualization()