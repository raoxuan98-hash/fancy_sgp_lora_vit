## 一、主实验方案

### 1. 基准设置

#### (a) 跨域类增量学习（Cross-Domain Class-Incremental Learning）

我们将在跨域基准数据集 X-TAIL 上进行评估，该数据集包括以下 10 个域：

- aircraft, caltech101, dtd, eurosat, flowers, food101, mnist, oxford_pets, stanford_cars, ImageNet-R。

每个域视为一个独立任务，每个任务的每个类别采集 `num_shots` 个样本作为训练集。

#### (b) 域内类增量学习（Within-Domain Class-Incremental Learning）

我们将在四个广泛使用的类增量学习（Class-Incremental Learning, CIL）基准数据集上进行评估。基础任务划分如下表所示：

| 数据集     | 任务划分                                    | 初始类别数 | 每任务新增类别数  | 总任务数 |
| ---------- | ------------------------------------------- | ---------- | ----------------- | -------- |
| CIFAR-100  | 10 tasks × 10 classes                       | 10         | 10                | 10       |
| ImageNet-R | 10 tasks × 20 classes                       | 20         | 20                | 10       |
| CUB-200    | 10 tasks × 20 classes                       | 20         | 20                | 10       |
| Cars-196   | 10 tasks × 20 classes + 1 task × 16 classes | 20         | 20 (最后任务: 16) | 11       |

**注**：上述设置与代码库中 `main.py` 的 `smart_defaults` 函数一致，可直接复用。默认主干架构为 `vit-b-p16-mocov3` 预训练 ViT；后续将扩展至 `vit-b-p16` 和 `vit-b-p16-clip` 等变体，以验证方法泛化性。


### 2. 对比方法

我们选取以下代表性方法作为基线，进行全面对比：

1. **LoRA（基础版本）**：采用 `basic_lora` 配置。
2. joint-training：经验上界
3. 预训练表征 + linear prohebing。
4. **LoRA + 知识蒸馏**：设置 `gamma_kd=0.5/1.0`，`update_teacher_each_task=True`，`distillation_transform='identity'`；使用余弦相似度蒸馏（不使用特征蒸馏）。
5. LoRA + NSP：显式的梯度投影，不是构建参数化的零空间投影，而是设计梯度钩子：在反向传播的过程修改梯度。其投影矩阵的设计可参考LoRA-NSP
6. LoRA + SGP：显式的梯度投影。
7. **LoRA-NSP**：使用 `nsp_lora` 类型，测试 `nsp_weight=0.00`（退化为普通 LoRA，可塑性较低）和 `nsp_weight=0.10`（可塑性较高）。
8. **LoRA-SGP**：默认 `weight_kind="log1p"`；测试 `weight_p=1.0, weight_k=1.0` 和 `weight_p=2.0, weight_k=2.0` 两种配置。

**注**：每个方法均收集有/无 AMDC 以及 LDA/QDA 分类器的结果。为确保公平，所有方法统一使用 **RGDA 分类器** 进行最终评估。虽然支持多种分布补偿策略（如线性变换、弱非线性变换及 Hopfield 变换），但主实验仅报告“无补偿”和“AMDC 补偿”两种情形。因此，总计方法变体 × 补偿策略 = (1 + 1 + 2 + 2) × 2 = 12 组结果。

### 3. 评估指标

采用以下两个核心指标评估模型性能：

- **Last-Acc**：完成所有任务后，在全部类别上的平均分类准确率，反映最终性能。
- **Avg-Acc**：每个任务结束后，在所有已见类别上的准确率的平均值，反映整体稳定性。
- Improment：有AMDC的情况下，相较于无AMDC的baseline，其提升的性能，反应后补偿对可塑性-稳定性的影响。

### 4. 预期结论

我的预期结论是：

1. 从无后补偿AMDC的角度看：LoRA取得的效果总体上最差，LoRA-NSP取得的总体结果最好。因为其优化过程没有任何保护措施，模型主干的参数发生了很大的偏移，因此重构后的分类器的精度会比较差。LoRA-NSP可能会取得比较好的结果，甚至可能会比LoRA-SGP更好？因为LoRA-NSP享有的稳定性更好，在没有后补偿AMDC的情况下，LoRA-NSP因其较优的稳定性性能最好。LoRA-SGP次之，因为加权投影矩阵的缘故，其可塑性强了，但在没有后补偿的情况下，其性能不如LoRA-NSP。
2. 有后补偿AMDC的情况下看：在不修改主干优化的情况下，AMDC能以post-hoc的方式显著提高所有所有方法的原有性能。LoRA + AMDC相较于LoRA的提升幅度最大，因为LoRA的可塑性最高。LoRA-SGP + AMDC相较于LoRA-SGP的提升幅度虽然比LoRA + AMDC和LoRA的差，但因为其更好的可塑性-稳定性平衡，其在AMDC的加持下取得了最好的性能。LoRA-NSP + AMDC相较于LoRA-NSP的提升最小，因为其稳定性太强了，导致其在学习新任务的适合不能有效吸收特定任务的知识，导致LoRA-NSP + AMDC < LoRA-SGP + AMDC。我们将在消融实验中更加具体地研究
3. 就零空间投影而言，参数化的零空间投影比在计算完梯度再投影的零空间投影效果更好，这种好处得益于参数化的零空间投影在信息的前向传播过程就已经对信息进行了重加权，这比使用全信息计算完梯度后，再对梯度进行修正的传统方法更好。后者梯度修正过程会损害可塑性的提高。
4. 我们从有后补偿AMDC的角度看，再加入后补偿AMDC后，很多结论会被颠覆。原有的研究大部分仅仅只沿着结论1的角度研究，或者仅仅使用一种方法，沿着结论2的角度进行研究。我们的实验表明，后补偿与主干抑制遗忘的方法相辅相成，应该共同考虑，这是未来学术界可考虑的方向。

---

## 二、消融研究方案

消融研究旨在系统分析各组件的作用及其交互影响。以下从组件级、超参数级和机制级展开。因为消融实验使用的数据集到底是Within-domain数据集还是Cross-domain数据集，我们暂时还没有结论。因此完成主要实验后确定。我现在跟倾向于使用Cross-domain CIL数据集作为消融实验的数据集，这样我们不用挨个跑这么多within-domain的实验。

### 1. 组件消融

下表总结组件消融变体：

| 变体        | LoRA-SGP | AMDC | 实现方式说明          |
| ----------- | -------- | ---- | --------------------- |
| Full Method | ✅        | ✅    | 默认配置              |
| w/o SGP     | ❌        | ✅    | 替换为 `basic_lora`   |
| w/o AMDC    | ✅        | ❌    | 禁用分布补偿          |
| w/o Both    | ❌        | ❌    | `basic_lora` + 无补偿 |

**注**：仅当微调策略变更时需重新训练；否则可在同一训练轨迹下报告不同补偿/分类器结果。若需对比 SGD-based 分类器，可在 `classifier_builder.py` 中设置 `classifier_type = ['sgd', 'lda', 'qda']`，系统自动输出多类结果。

#### 评价

我在思考这个组件消融实验的必要性。因为主试验已经包含了这部分的实验结果了。

### 2. LoRA-SGP 与 AMDC 的联合分析

**动机**：后补偿可弥补可塑性提升带来的负面影响。我们将定量研究可塑性-稳定性变化对分类器的影响。这部分的实验是对主实验预期结论2的扩展。在这里，我们通过动态调整LoRA-NSP和LoRA-SGP的超参数，定量地调整主干在优化过程的可塑性和稳定性，并定量地记录有无AMDC补偿的情况下类增量学习的性能变换。我期望这部分给出的是一种折线图的变换，体现有无AMDC情况下，准确度的变化的消融情况。可以预见的是，在无AMDC的情况下，随着可塑性的增强，准确度会下降。在有AMDC的情况，随着可塑性的增强，准确度先提高再下降。而且AMDC准确度提高的参数区间，无AMDC是持续下降的。这意味着后补偿带来的独特优势依赖于较高的可塑性。

#### 预期结论

在有AMDC补偿的情况下，系统的性能虽可塑性的提高先提高再下降。在AMDC性能提高的部分，无AMDC的曲线持续下降。从这两个曲线，我们可以辨识出三个超参数拐点：第一个拐点是AMDC提高到顶点的位置，第二个拐点是AMDC与无AMDC性能差异最大化的拐点。第三个拐点是无AMDC性能达到顶点的位置。我猜想这三个拐点的位置可能各不相同。

### 3. LoRA-SGP 超参数消融

![权重函数对不同奇异值下的奇异方向信息的“过滤作用”](https://cdn.nlark.com/yuque/0/2025/png/57388852/1762315395949-fa8648ea-7484-4da8-9a58-6ad174afb703.png)

#### (a) 权重函数敏感性分析

- 测试 `weight_temp ∈ {1.0, 2.0, 4.0}` 和 `weight_p ∈ {1.0, 2.0}` 对性能的影响。
- 预期：不同数据集对超参数敏感性存在差异，需分别调优。

#### (b) 权重函数形式对比（Weight Kind Ablation）

- 对比不同 `weight_kind`（如对数衰减、指数衰减）对稳定性-可塑性权衡的影响。
- **实验范围**：为控制成本，仅在 ImageNet-R（大尺度通用数据）和 Cars-196（细粒度场景）上进行。
- **报告方式**：统一报告有/无 AMDC 时的性能，以体现模块协同效应。使用热力图或分组柱状图展示超参数-性能关系，避免堆砌表格。

### 4. AMDC 消融实验

#### (a) 内部机制分析

- **仅补偿均值**（固定 Σ，更新 μ）。
- **仅补偿协方差**（固定 μ，更新 Σ）。
- **同时补偿均值与协方差**（Full AMDC）。
- **不同注意力温度 τ 的影响**。

#### (b) 与其他补偿方法对比

- 对比 LDC / Linear / WeakNonlinear / Nonlinear Transform 与 AMDC 的：
  - **精度表现**（主实验中部分覆盖）。
  - **计算效率**：固定类别数（如 50, 100, 150, 200），测量补偿阶段运行时间，绘制类别数-时间曲线或柱状图，突出 AMDC 的训练无关优势。
    ![画板](https://cdn.nlark.com/yuque/0/2025/jpeg/57388852/1762316876844-b5fbc399-4dea-4948-8ccc-5008e45fefaf.jpeg)

#### (c) AMDC 对其他方法的促进作用

- 对 LoRA 的促进。
- 对 NSP-LoRA 的促进。
- 对 LoRA + Distillation 的促进。

**注**：此部分可在主实验中体现。结论：AMDC 对可塑性强/弱的抗遗忘方法均有正面作用，对可塑性强的补偿效果更显著。

### 5. 分类器消融实验
在分类器消融实验，我已经构建了基本的demo。具体而言，我希望做到下面的内容：

这个消融实验不检验各个分类器在增量学习阶段的性能。我们想检验在预训练表征或者joint-leanring表征的情况下，对分布的协方差矩阵进行正则化，对各种分类器的影响。特别地，我们现在构建的RGDA分类器的协方差矩阵是类别特定的协方差矩阵 + 全局平均协方差矩阵 + 单位矩阵。三者的贡献系数分别为\alpha_1, \alpha_2 , \alpha_3。在我们的前置实验中，我们发现\alpha_3对性能的影响不大，所以我将其固定为0.5。\alpha_1和\alpha_2的影响很大，而且\alpha_2 > 1.0的时候，效果更好，这意味着\alpha_1 + \alpha_2并不要求是常值。
1. 对于一个固定的架构，例如vit-b-p16，\alpha_1和\alpha_2从[0, 5.0]分别取值，然后绘制性能曲面的等高线图。这个性能曲面可以是cross-domain数据集准确度的平均值。
2. 为了体现\alpha_1和\alpha_2对不同架构的影响，同时避免绘制太多的图片（不利于放在论文中）。我们可以让\alpha_1 + \alpha_2 = 常数。这个常数可以取自实验1的数值。或者我们可以固定\alpha_1，变动\alpha_2；固定\alpha_2，变动\alpha_1。这样能够看出性能对\alpha_1和\alpha_2参数的敏感性，同时不同的架构还能画在一起。


3. 实验1和2是检验了RGDA对不同参数的敏感性。我们需要将其推广到基于SGD迭代优化的分类器中。SGD分类器的性能曲线可能和RGDA一样。如果趋势一样，我们就说对协方差的重加权本身就丰富了近似分布涵盖的信息丰富度，这与使用什么分类器无关。如果趋势不太一样，我们就强调每种分类器对协方差信息富集程度的敏感程度不同。同时，我们还可以把NCM、LDA作为一个baseline：画两条横杠在图上。LDA可以看作是\alpha_1= 0的RGDA变体。
4. 同时，我们还要对比使用RGDA分类器与SGD分类器在重构分类器和预测环节的时间耗时对比，突出RGDA分类器的计算效率。这个计算效率得分开，显示重构的耗时和预测的耗时。
5. 作图应该符合IEEE双栏的单栏图片的格式，不要使用Type3字体，使用Type1/2字体。
---

## 三、补充实验方案

补充实验旨在验证方法的扩展性和鲁棒性。

### 1. 长序列任务实验（Long-Sequence within-domain CIL）

- 将不同数据集划分为 20 个任务（每任务 5 类），评估长期增量学习中的稳定性和抗遗忘能力。
- 重点关注 Avg-Acc 的衰减速率与最终性能下限。

### 2. 跨架构泛化性（Cross-Architecture Generalization）

- 在相同任务设置下，切换主干 ViT 的预训练来源（MoCo v3 / DINO / CLIP）。
- 验证 LoRA-SGP + RGDA + AMDC 框架对不同预训练特征空间的鲁棒适应能力。

### 四、代码补充

1. 目前有些代码并没有实现，需要检查并且实现。